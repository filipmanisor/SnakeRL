{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idei:\n",
    "* x Overfitting: schimbat dropout\n",
    "* x Fixed Q target\n",
    "* x Double DNN\n",
    "* x O mica recompensa negativa pentru STILL_ALIVE, poate il va determina sa faca mai putini pasi random\n",
    "* x Adauga limita maxima de timp pentru online training. De exemplu, dupa 50s (fara schimbare de scor?), toate mutarile devin DOWN, ca sa iasa din tabla.\n",
    "\n",
    "\n",
    "* Testat diferite modele pentru input actiune\n",
    "* Testat diferite arhitecturi\n",
    "\n",
    "\n",
    "* Normalizare date\n",
    "* Dueling DQN\n",
    "* Gamma mai mare\n",
    "* Considerat invatare online doar pe ultimele exemple (max memory = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "from PIL import Image, ImageOps\n",
    "from keras.models import Sequential, Model\n",
    "import keras.layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "import keras.losses as losses\n",
    "from keras.models import load_model\n",
    "from keras.backend import set_image_data_format\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import glob\n",
    "from collections import deque\n",
    "\n",
    "set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "STILL_ALIVE_REWARD = -0.01\n",
    "STILL_ALIVE = -0.05\n",
    "DEAD_REWARD = -1\n",
    "SCORE_REWARD = 1\n",
    "REWARD_POSITION = 3\n",
    "\n",
    "CROP_SHAPE = (750, 539, 1)\n",
    "RESIZE_WIDTH = 100\n",
    "RESIZE_HEIGHT = 71\n",
    "READ_BATCH = 2\n",
    "\n",
    "MOVES = 4\n",
    "RIGHT = 0\n",
    "DOWN = 1\n",
    "LEFT = 2\n",
    "UP = 3\n",
    "\n",
    "SHOTS_FOLDER = 'data/shots/'\n",
    "EXP_FOLDER = 'data/experience/'\n",
    "EVAL_FOLDER = 'data/exp_eval/'\n",
    "\n",
    "SAMPLE_ALIVE = 1\n",
    "SAMPLE_DEAD = 5\n",
    "SAMPLE_REWARD = 20\n",
    "\n",
    "MAX_MEMORY = 500\n",
    "MAX_PLAY = 30\n",
    "\n",
    "GAMMA = 0.9\n",
    "LEARNING_RATE = 0.0001\n",
    "EPS_INIT = 1.0\n",
    "EPS_MIN = 0.05\n",
    "EPS_DECAY = 0.998\n",
    "CLONE_STEPS = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectLevel(l):\n",
    "    xpath = '/html/body/section/div[2]/nav/p[' + str(l+1) + ']'\n",
    "    \n",
    "    level = browser.find_element_by_xpath(xpath)\n",
    "    level.click()\n",
    "    \n",
    "    \n",
    "def clickBoard(board):        \n",
    "    try:\n",
    "        board.click()\n",
    "    except WebDriverException:\n",
    "        print('Exception')\n",
    "        return\n",
    "    \n",
    "    \n",
    "def saveScreen(fileName):    \n",
    "    state = getState()\n",
    "#     if state == 'playing' or state == 'paused':    \n",
    "    ss = browser.get_screenshot_as_file(SHOTS_FOLDER + fileName)\n",
    "    \n",
    "    \n",
    "def getScreen():\n",
    "    ss = browser.get_screenshot_as_png()\n",
    "    im = Image.open(io.BytesIO(ss))\n",
    "    \n",
    "    im = preprocImg(im)\n",
    "    return np.asarray(im.convert(\"L\"))\n",
    "    \n",
    "    \n",
    "def getState():\n",
    "    xpath = '/html/body/section/div[2]'\n",
    "    state = browser.find_element_by_xpath(xpath)\n",
    "    c = state.get_attribute('class')\n",
    "    \n",
    "    return c.split(' ')[-1]\n",
    "\n",
    "\n",
    "def getScore():\n",
    "    state = getState()\n",
    "    \n",
    "    if state == 'playing' or state == 'paused':\n",
    "        \n",
    "        xpath = '/html/body/section/div[2]/p[1]/span'\n",
    "        score = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "        if not score.text.isnumeric():\n",
    "            return 0\n",
    "        return int(score.text)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def getBoard():\n",
    "    xpath = '/html/body/section/div[2]/div'\n",
    "    board = browser.find_element_by_xpath(xpath)\n",
    "    \n",
    "    return board\n",
    "\n",
    "\n",
    "def makeMove(board, m):    \n",
    "    \n",
    "    if m == RIGHT:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_RIGHT)\n",
    "    elif m == DOWN:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_DOWN)\n",
    "    elif m == LEFT:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_LEFT)\n",
    "    elif m == UP:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_UP)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cropImgOld(fileName):\n",
    "    ss = plt.imread(fileName)\n",
    "\n",
    "    ss = ss[120:659, 273:1023, :]\n",
    "    \n",
    "    plt.imsave(fileName, ss)\n",
    "\n",
    "\n",
    "def saveImage(arr, file):\n",
    "    '''Save an image array to a file'''\n",
    "    img = Image.fromarray(arr.astype(np.uint8))\n",
    "    img.save(file)\n",
    "        \n",
    "\n",
    "def preprocImg(im):\n",
    "    '''Preprocess a screenshot.'''     \n",
    "    # Crop board\n",
    "    im = im.crop((273, 120, 1023, 659))\n",
    "    \n",
    "    # Grayscale\n",
    "    im = ImageOps.grayscale(im)\n",
    "    \n",
    "    # Binarization\n",
    "    t = 127\n",
    "    im = im.point(lambda x: 255 if x > t else 0)\n",
    "    \n",
    "    # Resize\n",
    "    im = im.resize((RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "    \n",
    "    return im\n",
    "    \n",
    "    \n",
    "def preprocAll(gameIndex):\n",
    "    '''Preprocess all screenshots in the data folder.'''\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    for f in files:\n",
    "        g = parseName(f)[0]\n",
    "        \n",
    "        if g >= gameIndex:        \n",
    "            fileName =  SHOTS_FOLDER + f\n",
    "            im = Image.open(fileName)   \n",
    "            im = preprocImg(im)\n",
    "            im.save(fileName)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN action output\n",
    "\n",
    "Functional API, citeste batch-uri de imagini, considera actiunea ca output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nn_model_actionoutput():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Action as output, final layer has as many neurons as possible actions.'''\n",
    "    \n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv1')(screen_input)\n",
    "#     conv = Conv2D(16, (4, 4), activation='relu', name='conv2')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool1')(conv)\n",
    "    \n",
    "    conv = Conv2D(32, (4, 4), activation='relu', name='conv3')(pool)\n",
    "#     conv = Conv2D(8, (4, 4), activation='relu', name='conv4')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool2')(conv)\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv5')(pool)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(pool)\n",
    "    dense = Dense(100, activation='relu', name='dense1')(flat)\n",
    "    drop = Dropout(rate=0.0, name='dropout1')(dense)\n",
    "    dense = Dense(40, activation='relu', name='dense2')(drop)\n",
    "    drop = Dropout(rate=0.0, name='dropout2')(dense)\n",
    "    \n",
    "    output = Dense(MOVES, activation='linear', name='output')(drop)\n",
    "    \n",
    "    model = Model(inputs=screen_input, outputs=output)\n",
    "    \n",
    "    optimizer = Adam(lr=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def nn_model_nopool():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Action as output, final layer has as many neurons as possible actions.\n",
    "    Does not use pooling layers, only strides.'''\n",
    "    \n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), strides=(2, 2), activation='relu', name='conv1')(screen_input)    \n",
    "    conv = Conv2D(32, (4, 4), strides=(2, 2), activation='relu', name='conv2')(conv)    \n",
    "    conv = Conv2D(16, (4, 4), strides=(2, 2), activation='relu', name='conv3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(conv)\n",
    "    dense = Dense(100, activation='relu', name='dense1')(flat)\n",
    "    drop = Dropout(rate=0.0, name='dropout1')(dense)\n",
    "    dense = Dense(40, activation='relu', name='dense2')(drop)\n",
    "    drop = Dropout(rate=0.0, name='dropout2')(dense)\n",
    "    \n",
    "    output = Dense(MOVES, activation='linear', name='output')(drop)\n",
    "    \n",
    "    model = Model(inputs=screen_input, outputs=output)\n",
    "    \n",
    "    optimizer = Adam(lr=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def nn_model_deepmind():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Previous action as input.\n",
    "    Action as output, final layer has as many neurons as possible actions.\n",
    "    The structure of the NN is based on the one used by DeepMind.'''\n",
    "    \n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(32, (8, 8), strides=(4, 4), activation='relu', name='conv1')(screen_input)\n",
    "    conv = Conv2D(64, (4, 4), strides=(2, 2), activation='relu', name='conv2')(conv)\n",
    "    conv = Conv2D(64, (3, 3), activation='relu', name='conv3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(conv)\n",
    "    dense = Dense(512, activation='relu', name='dense')(flat)   \n",
    "    \n",
    "    action_input = Input(shape=(1,), name='action_input')\n",
    "    concat = keras.layers.concatenate([flat, action_input])\n",
    "    \n",
    "    output = Dense(MOVES, activation='linear', name='output')(concat)\n",
    "    \n",
    "    model = Model(inputs=[screen_input, action_input], outputs=output)\n",
    "    \n",
    "    optimizer = RMSprop(lr=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = optimizer)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experience class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Experience:\n",
    "    '''Class for an experience.'''    \n",
    "    \n",
    "    def __init__(self, state=[], prevAction=0, action=0, label=0, nextState=[]):\n",
    "        self.state = state\n",
    "        self.prevAction = prevAction\n",
    "        self.action = action\n",
    "        self.label = label\n",
    "        self.nextState = nextState\n",
    "        \n",
    "        \n",
    "    def save(self, folder, index):\n",
    "        '''Save experience to a file.'''\n",
    "\n",
    "        file = folder + str(index).zfill(4) + '_' + str(self.prevAction) + '_' + str(self.action) + '_' + str(self.label) + '.xp'\n",
    "        f = open(file, 'w')\n",
    "\n",
    "        for s in self.state:\n",
    "            list = s.flatten()\n",
    "            for l in list:\n",
    "                f.write(str(l) + ' ')\n",
    "            f.write('\\n')\n",
    "\n",
    "        for s in self.nextState:\n",
    "            list = s.flatten()\n",
    "            for l in list:\n",
    "                f.write(str(l) + ' ')\n",
    "            f.write('\\n')\n",
    "\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    def readArray(self, line):\n",
    "        '''Read an array representing an screenshot from a file.'''\n",
    "        elems = line.split(' ')[:-1]\n",
    "\n",
    "        a = []\n",
    "        for e in elems:\n",
    "            a.append(int(e))\n",
    "\n",
    "        a = np.asarray(a)\n",
    "        a = a.reshape(RESIZE_HEIGHT, RESIZE_WIDTH)\n",
    "\n",
    "        return a\n",
    "\n",
    "    \n",
    "    def read(self, folder, file):\n",
    "        '''Read an experience from a file.'''\n",
    "        f = open(folder + file, 'r')\n",
    "\n",
    "        elems = parseExpName(file)\n",
    "        self.prevAction = int(elems[1])\n",
    "        self.action = int(elems[2])\n",
    "        self.label = float(elems[3])\n",
    "\n",
    "        s1 = self.readArray(f.readline())\n",
    "        s2 = self.readArray(f.readline())\n",
    "        self.state = [s1, s2]\n",
    "\n",
    "        ns1 = self.readArray(f.readline())\n",
    "        ns2 = self.readArray(f.readline())\n",
    "        self.nextState = [ns1, ns2]\n",
    "\n",
    "        f.close()\n",
    "                        \n",
    "            \n",
    "def rememberExp(memory, exps):\n",
    "    '''Add new experiences to the memory.'''\n",
    "    for e in exps:\n",
    "        if len(memory) == MAX_MEMORY:\n",
    "            memory.pop(0)\n",
    "        memory.append(e)\n",
    "\n",
    "\n",
    "def sampleMemory(memory, nSamples, propD, propR, propA):\n",
    "    '''Sample experiences from the memroy according to some proportions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    memory: the remembered experiences\n",
    "    nSamples: total number of samples\n",
    "    propD: proportion of samples which represent a death\n",
    "    propR: proportion of samples which represent a reward\n",
    "    propA: proportion of rest of samples\n",
    "    '''\n",
    "    \n",
    "    nSamples = min(len(memory), nSamples)\n",
    "        \n",
    "    perc = []\n",
    "    nd, na, nr = (0, 0, 0)\n",
    "    for exp in memory:\n",
    "        r = float(parseExpName(f)[REWARD_POSITION])\n",
    "        if r == DEAD_REWARD:\n",
    "            perc.append('d')\n",
    "            nd += 1\n",
    "        elif r == STILL_ALIVE:\n",
    "            perc.append('a')\n",
    "            na += 1\n",
    "        else:\n",
    "            perc.append('r')\n",
    "            nr += 1\n",
    "        \n",
    "    n = propD * nd + propA * na + propR * nr\n",
    "    pd = propD / n\n",
    "    pa = propA / n\n",
    "    pr = propR / n\n",
    "    for i in range(len(perc)):\n",
    "        if perc[i] == 'd':\n",
    "            perc[i] = pd\n",
    "        elif perc[i] == 'a':\n",
    "            perc[i] = pa\n",
    "        else:\n",
    "            perc[i] = pr\n",
    "        \n",
    "    samples = np.random.choice(memory, size=nSamples, replace=False, p=perc)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def parseExpName(file):\n",
    "    return file[:-3].split('_')\n",
    "\n",
    "\n",
    "def sampleFiles(nSamples,\n",
    "                folder=EXP_FOLDER,\n",
    "                propD=SAMPLE_DEAD, \n",
    "                propR=SAMPLE_REWARD,\n",
    "                propA=SAMPLE_ALIVE):\n",
    "    '''Sample the experience files according to some proportions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nSamples: total number of samples\n",
    "    folder: the experience folder\n",
    "    propD: proportion of samples which represent a death\n",
    "    propR: proportion of samples which represent a reward\n",
    "    propA: proportion of rest of samples\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(folder)\n",
    "    nSamples = min(nSamples, len(files))\n",
    "    \n",
    "    perc = []\n",
    "    nd, na, nr = (0, 0, 0)\n",
    "    for f in files:\n",
    "        r = float(parseExpName(f)[REWARD_POSITION])\n",
    "        if r == DEAD_REWARD:\n",
    "            perc.append('d')\n",
    "            nd += 1\n",
    "        elif r == STILL_ALIVE:\n",
    "            perc.append('a')\n",
    "            na += 1\n",
    "        else:\n",
    "            perc.append('r')\n",
    "            nr += 1\n",
    "        \n",
    "    n = propD * nd + propA * na + propR * nr\n",
    "    pd = propD / n\n",
    "    pa = propA / n\n",
    "    pr = propR / n\n",
    "    for i in range(len(perc)):\n",
    "        if perc[i] == 'd':\n",
    "            perc[i] = pd\n",
    "        elif perc[i] == 'a':\n",
    "            perc[i] = pa\n",
    "        else:\n",
    "            perc[i] = pr\n",
    "        \n",
    "    samples = np.random.choice(files, size=nSamples, replace=False, p=perc)\n",
    "    print('Sampled data.')\n",
    "    return samples\n",
    "\n",
    "\n",
    "def readSamples(samples):\n",
    "    '''Read samples from experience files.'''\n",
    "    states = []\n",
    "    prevActions = []\n",
    "    actions = []\n",
    "    labels = []\n",
    "    nextStates = []\n",
    "    \n",
    "    for i, file in enumerate(samples):    \n",
    "        exp = Experience()\n",
    "        exp.read(EXP_FOLDER, file)\n",
    "            \n",
    "        states.append(exp.state)\n",
    "        prevActions.append(exp.prevAction)\n",
    "        actions.append(exp.action)\n",
    "        labels.append(exp.label)\n",
    "        nextStates.append(exp.nextState)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "    states = np.asarray(states)\n",
    "    prevActions = np.asarray(prevActions)\n",
    "    actions = np.asarray(actions)\n",
    "    nextStates = np.asarray(nextStates)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    return states, prevActions, actions, labels, nextStates\n",
    "\n",
    "\n",
    "def getLastExpIndex(folder):\n",
    "    '''Get the index of the last experience.'''\n",
    "    files = os.listdir(folder)\n",
    "    if len(files) == 0:\n",
    "        return 0\n",
    "\n",
    "    last = files[-1]\n",
    "    index = parseExpName(last)[0]\n",
    "    \n",
    "    return int(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluateLabels(model, states, prevActions, actions, labels, sample=0):\n",
    "    \n",
    "    if sample > 0:\n",
    "        sample = min(sample, len(states))\n",
    "        indexes = random.sample(range(len(states)), sample)\n",
    "        states = states[indexes]\n",
    "        prevActions = prevActions[indexes]\n",
    "        actions = actions[indexes]\n",
    "        labels = labels[indexes]\n",
    "        \n",
    "    res = model.predict([states, prevActions])   \n",
    "    \n",
    "    sqErr = [(res[i][actions[i]] - labels[i])**2 for i, out in enumerate(res)]\n",
    "    meanSqErr = np.mean(sqErr)\n",
    "    \n",
    "    return meanSqErr\n",
    "\n",
    "\n",
    "def evaluateRewardLabels(model, samples, evalFolder=EVAL_FOLDER):\n",
    "    '''Evaluate the model only using Reward and Death experiences.\n",
    "    Reads experiences from evaluation folder.'''\n",
    "    \n",
    "    states = []\n",
    "    prevActions = []\n",
    "    actions = []\n",
    "    labels = []\n",
    "    nextStates = []\n",
    "        \n",
    "    files = os.listdir(evalFolder)\n",
    "    samples = min(samples, len(files))\n",
    "    \n",
    "    for f in files:\n",
    "        exp = Experience()\n",
    "        exp.read(evalFolder, f)\n",
    "        \n",
    "        states.append(exp.state)\n",
    "        prevActions.append(exp.prevAction)\n",
    "        actions.append(exp.action)\n",
    "        labels.append(exp.label)\n",
    "        nextStates.append(exp.nextState)\n",
    "    \n",
    "    res = model.predict([states, prevActions])   \n",
    "    \n",
    "    sqErr = [(res[i][actions[i]] - labels[i])**2 for i, out in enumerate(res)]\n",
    "    meanSqErr = np.mean(sqErr)\n",
    "    \n",
    "    return meanSqErr\n",
    "\n",
    "    \n",
    "def moveString(m):\n",
    "    if m == RIGHT:\n",
    "        return 'right'\n",
    "    elif m == DOWN:\n",
    "        return 'down '\n",
    "    elif m == LEFT:\n",
    "        return 'left '\n",
    "    elif m == UP:\n",
    "        return 'up   '\n",
    "    else:\n",
    "        return 'none '\n",
    "    \n",
    "    \n",
    "def getMoveOutputEps(model, screens, prevAction, eps):\n",
    "    '''Get the move from the model which produces move scores as outputs, with an epsilon probability for exploration.'''\n",
    "    \n",
    "    # If there is a model\n",
    "    if model != False:        \n",
    "        p = random.random()\n",
    "        \n",
    "        # If exploitation was chosen\n",
    "        if p > eps:\n",
    "            res = model.predict([np.asarray([screens]), np.asarray([prevAction])])\n",
    "            m = np.argmax(res)\n",
    "            print('Model:', moveString(m), end='\\r')\n",
    "\n",
    "            return m\n",
    "   \n",
    "    # If there is no model or exploration was chosen\n",
    "    m = int(MOVES * random.random())\n",
    "    print('Rando:', moveString(m), end='\\r')\n",
    "    \n",
    "    return m \n",
    "\n",
    "\n",
    "def copyModel(model, func):\n",
    "    '''Copy a model and its weights.'''\n",
    "    newModel = func()\n",
    "    newModel.set_weights(model.get_weights())\n",
    "    \n",
    "    return newModel\n",
    "    \n",
    "\n",
    "def trainModelOnline(memory, \n",
    "                     model,\n",
    "                     targetModel,\n",
    "                     batchSize=32, \n",
    "                     batches=1,\n",
    "                     file='data/models/model.h5',\n",
    "                     status=True,\n",
    "                     modelFunc=nn_model_actionoutput\n",
    "                     ):\n",
    "    '''Train a model online, from the experience memory. \n",
    "    Saves the model at the end.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    memory: the experience memory\n",
    "    model: the model to be trained\n",
    "    targetModel: the fixed Q target model\n",
    "    batchSize: the training batch size\n",
    "    batches: number of batches to train on\n",
    "    file: the model file, used for saving\n",
    "    status: if true, print the status of the training\n",
    "    modelFunc: the type of model to use, given by the model creation function\n",
    "    '''\n",
    "    \n",
    "    global trainCount\n",
    "        \n",
    "    # Sample experiences from the memory\n",
    "    samples = sampleMemory(memory, batches * batchSize, SAMPLE_DEAD, SAMPLE_REWARD, SAMPLE_ALIVE)\n",
    "    batchSize = min(batchSize, len(samples))\n",
    "    \n",
    "    # For each batch\n",
    "    bStart = 0\n",
    "    \n",
    "    while bStart < len(samples):\n",
    "        \n",
    "        bStop = min(bStart + batchSize, len(samples))\n",
    "    \n",
    "        states = []\n",
    "        prevActions = []\n",
    "        targets = []\n",
    "        \n",
    "        # For each experience\n",
    "        while bStart < bStop: \n",
    "            e = samples[bStart]\n",
    "            s = e.state\n",
    "            p = e.prevAction\n",
    "            a = e.action\n",
    "            target = e.label\n",
    "            n = np.asarray([e.nextState])\n",
    "            \n",
    "            if target != DEAD_REWARD:\n",
    "                if target == STILL_ALIVE:\n",
    "                    target = STILL_ALIVE_REWARD     \n",
    "                    \n",
    "                # Fixed Q target and Double DQN       \n",
    "                bestAction = 0\n",
    "                bestNextAction = - np.Infinity\n",
    "                for m in range(MOVES):\n",
    "                    action = np.argmax(model.predict([n, np.asarray([m])]))\n",
    "                    if action > bestNextAction:\n",
    "                        bestNextAction = action\n",
    "                        bestAction = m\n",
    "                \n",
    "                target = target + GAMMA * targetModel.predict([n, np.asarray([bestAction])])[0][bestNextAction]\n",
    "\n",
    "            fullTarget = model.predict([np.asarray([s]), np.asarray([p])])\n",
    "            fullTarget[0][a] = target\n",
    "\n",
    "            targets.append(fullTarget[0])\n",
    "            states.append(s)\n",
    "            prevActions.append(p)\n",
    "                        \n",
    "            trainCount += 1\n",
    "            # Clone target model\n",
    "            if trainCount % CLONE_STEPS == 0:\n",
    "                targetModel = copyModel(model, modelFunc)            \n",
    "            \n",
    "            bStart += 1\n",
    "\n",
    "        # Fit the model with the batch\n",
    "        targets = np.asarray(targets)    \n",
    "        model.train_on_batch([states, prevActions], targets)\n",
    "        \n",
    "        bStart = bStop\n",
    "        \n",
    "    model.save(file)\n",
    "                \n",
    "    return model\n",
    "\n",
    "\n",
    "def trainModelOffline(states, prevActions, actions, labels, nextStates, \n",
    "                      epochs, \n",
    "                      batchSize=32, \n",
    "                      file='data/models/model.h5', \n",
    "                      load=False,\n",
    "                      status=True,\n",
    "                      modelFunc=nn_model_actionoutput\n",
    "                     ):\n",
    "    '''Train a model offline. \n",
    "    Can load or generate a new model. Saves the model after each epoch.\n",
    "    Implements Fixed Q-target.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    states: the list of batches of images representing the current states\n",
    "    prevActions: the list of previous actions taken\n",
    "    actions: the list of actions taken\n",
    "    labels: the list of rewards obtained\n",
    "    nextStates: the list of batches of images representing the next states\n",
    "    epochs: the number of training epochs\n",
    "    batchSize: the training batch size\n",
    "    file: the model file, used for saving and loading\n",
    "    load: if true, the model is loaded from the file, otherwise a new model is generated\n",
    "    status: if true, print the status of the training\n",
    "    modelFunc: the type of model to use, given by the model creation function\n",
    "    '''\n",
    "    \n",
    "    if load:\n",
    "        model = load_model(file)\n",
    "        print('Model loaded.')\n",
    "    else:\n",
    "        model = modelFunc()\n",
    "        \n",
    "    # Initialize the target model\n",
    "    targetModel = copyModel(model, modelFunc)\n",
    "\n",
    "    dataSize = len(states)\n",
    "    \n",
    "    # For each epoch\n",
    "    for i in range(epochs):\n",
    "        if status:\n",
    "            print('Epoch', i+1)\n",
    "        \n",
    "        time1 = time.time()\n",
    "    \n",
    "        batchStart = 0\n",
    "        batchEnd = min(batchSize, dataSize)\n",
    "    \n",
    "        # For each batch\n",
    "        while batchStart < batchEnd:\n",
    "\n",
    "            targets = []\n",
    "            \n",
    "            b = batchStart\n",
    "            # For each experience of the batch, recalculate the targets according to the Q algorithm\n",
    "            while b < dataSize and b < batchEnd:\n",
    "                # Get the features of the experience\n",
    "                s = states[b:b+1]\n",
    "                p = prevActions[b]\n",
    "                a = actions[b]\n",
    "                l = labels[b]\n",
    "                n = nextStates[b:b+1]\n",
    "                \n",
    "                target = l\n",
    "                if l != DEAD_REWARD:\n",
    "                    if l == STILL_ALIVE:\n",
    "                        l = STILL_ALIVE_REWARD                    \n",
    "                    \n",
    "                    # Fixed Q target and Double DQN\n",
    "                    \n",
    "                    bestAction = 0\n",
    "                    bestNextAction = - np.Infinity\n",
    "                    for m in range(MOVES):\n",
    "                        action = np.argmax(model.predict([n, np.asarray([m])]))\n",
    "                        if action > bestNextAction:\n",
    "                            bestNextAction = action\n",
    "                            bestAction = m\n",
    "                    \n",
    "                    target = l + GAMMA * targetModel.predict([n, np.asarray([bestAction])])[0][bestNextAction]\n",
    "                \n",
    "                fullTarget = model.predict([s, np.asarray([p])])\n",
    "                fullTarget[0][a] = target\n",
    "                \n",
    "                targets.append(fullTarget[0])\n",
    "                \n",
    "                # Clone target model\n",
    "                if (i * len(states) + b) % CLONE_STEPS == 0:\n",
    "                    targetModel = copyModel(model, modelFunc)\n",
    "                \n",
    "                b += 1\n",
    "            \n",
    "            if status and batchStart % (batchSize * 2) == 0:\n",
    "                print(batchStart, '/', dataSize, end='\\r')\n",
    "                \n",
    "            # Fit the model with the batch\n",
    "            targets = np.asarray(targets)\n",
    "            model.train_on_batch([states[batchStart:batchEnd], prevActions[batchStart:batchEnd]], targets)\n",
    "\n",
    "            batchStart = batchEnd\n",
    "            batchEnd = min(batchEnd + batchSize, dataSize)\n",
    "          \n",
    "        if status:  \n",
    "            print(dataSize, '/', dataSize)\n",
    "#             print(\"  MSE = %.2f\" % evaluateLabels(model, states, prevActions, actions, labels, sample=50))\n",
    "            print(\"  MSE = %.2f\" % evaluateRewardLabels(model))\n",
    "        \n",
    "        time2 = time.time()\n",
    "        \n",
    "        if status:\n",
    "            print(\"  Duration: %.2f s\" % (time2- time1))\n",
    "            \n",
    "        # Save model every 10 epochs\n",
    "        if i % 2 == 0:\n",
    "            model.save(file) \n",
    "            \n",
    "      \n",
    "    model.save(file) \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def play(games,\n",
    "         train=False,\n",
    "         useModel=False,\n",
    "         saveExp=False,\n",
    "         modelFile='data/models/model.h5',\n",
    "         saveFolder=EXP_FOLDER,\n",
    "         modelFunc=nn_model_actionoutput):\n",
    "    \n",
    "    '''Makes a move every second tick. The previous action does not influence the current action.'''\n",
    "    \n",
    "    global browser\n",
    "    global trainCount\n",
    "    \n",
    "    e = EPS_INIT\n",
    "    \n",
    "    expIndex = getLastExpIndex(saveFolder) + 1\n",
    "    \n",
    "    url = 'https://playsnake.org/'\n",
    "    browser = webdriver.Chrome(executable_path='D:/Libraries/Drivers/chromedriver_win32/chromedriver.exe')\n",
    "#     browser = webdriver.Chrome(executable_path='C:/Personal/Proiecte/Cod/_libs/Python/selenium_chromedriver73_win32/chromedriver.exe')\n",
    "    browser.get(url) \n",
    "    memory = []\n",
    "    \n",
    "    # Load model\n",
    "    if useModel == True:\n",
    "        curModel = load_model(modelFile)\n",
    "        # Initialize the target model\n",
    "        targetModel = copyModel(curModel, modelFunc)\n",
    "    elif train == True:\n",
    "        curModel = modelFunc()\n",
    "        # Initialize the target model\n",
    "        targetModel = copyModel(curModel, modelFunc)\n",
    "    else:\n",
    "        curModel = False        \n",
    "\n",
    "    trainCount = 0\n",
    "    for g in range(games):\n",
    "\n",
    "        score = 0\n",
    "        screenIndex = 0\n",
    "        time1 = time.time()\n",
    "    \n",
    "        episode = []        \n",
    "        finalScore = 0\n",
    "\n",
    "        # Select the level\n",
    "        selectLevel(1)        \n",
    "        while getState() == 'countdown':\n",
    "            pass  \n",
    "        board = getBoard()      \n",
    "\n",
    "        clickBoard(board)\n",
    "        screens = deque([], 4)\n",
    "        moves = deque([], 3)\n",
    "        moves.append(DOWN)\n",
    "        \n",
    "        index = 0\n",
    "        \n",
    "        while getState() == 'playing' or getState() == 'paused':\n",
    "                \n",
    "            # Get current screenshot\n",
    "            screens.append(getScreen())            \n",
    "\n",
    "            # Calculate the reward for the previous move\n",
    "            r = STILL_ALIVE\n",
    "            if getScore() - score > 0:\n",
    "                r = SCORE_REWARD \n",
    "                # Reset time between rewards\n",
    "                time1 = time.time()\n",
    "                \n",
    "\n",
    "            score = getScore()\n",
    "            finalScore = max(finalScore, score)  \n",
    "            \n",
    "            if index > 1:\n",
    "                \n",
    "                # Form the current state\n",
    "                state = [screens[-2], screens[-1]]\n",
    "                \n",
    "                if index > 2:\n",
    "                    # Save experience\n",
    "                    prevState = [screens[0], screens[1]]\n",
    "                    exp = Experience(prevState, moves[0], moves[1], r, state)\n",
    "                    episode.append(exp)  \n",
    "                \n",
    "                # Check if max time between rewards has passed\n",
    "                time2 = time.time()  \n",
    "                if time2 - time1 > MAX_PLAY:\n",
    "                    # Just repeat the last move until ending the game\n",
    "                    print('Death:', moveString(m), end='\\r')\n",
    "                \n",
    "                else:                \n",
    "                    # Get the current move\n",
    "                    m = getMoveOutputEps(curModel, state, moves[-1], e)\n",
    "                    moves.append(m)\n",
    "                      \n",
    "            \n",
    "                # Send the move to the board\n",
    "                clickBoard(board)\n",
    "                makeMove(board, m)\n",
    "                clickBoard(board) \n",
    "                \n",
    "            else:\n",
    "                clickBoard(board)\n",
    "                clickBoard(board)                 \n",
    "\n",
    "            index += 1\n",
    "            \n",
    "        # Add last experience\n",
    "        if len(episode) > 1:\n",
    "            state = [screens[-1], screens[-1]]\n",
    "            prevState = [screens[1], screens[2]]\n",
    "            exp = Experience(prevState, moves[0], moves[1], DEAD_REWARD, state)\n",
    "            episode.append(exp)   \n",
    "            \n",
    "        print(\"%d: %d points \" % (g, finalScore))        \n",
    "        \n",
    "        # Save experiences\n",
    "        if saveExp:\n",
    "            # Only save experiences with positive rewards\n",
    "            hasReward = 0\n",
    "            for exp in episode:\n",
    "                if exp.label > 0:\n",
    "                    hasReward = 1\n",
    "                    break\n",
    "            if hasReward:\n",
    "                for exp in episode:\n",
    "                    exp.save(saveFolder, expIndex)\n",
    "                    expIndex += 1  \n",
    "            \n",
    "        if train:\n",
    "            # Add the episode to the memory\n",
    "            rememberExp(memory, episode)\n",
    "\n",
    "            # Retrain the model            \n",
    "            curModel = trainModelOnline(memory, model=curModel, targetModel=targetModel, \n",
    "                                        file=modelFile, batches=5, modelFunc=modelFunc)\n",
    "        else:\n",
    "            time.sleep(1)            \n",
    "            \n",
    "        if e > EPS_MIN:\n",
    "            e = e * EPS_DECAY\n",
    "\n",
    "    browser.quit()\n",
    "    \n",
    "    \n",
    "    ### DEBUGGING\n",
    "    return episode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train online\n",
    "EPS_INIT = 1.0\n",
    "EPS_MIN = 0.1\n",
    "EPS_DECAY = 0.997\n",
    "MAX_MEMORY = 5000\n",
    "episode = play(1000,\n",
    "               train=True,\n",
    "               useModel=True,\n",
    "               modelFunc=nn_model_deepmind,\n",
    "               modelFile='data/models/model2_deepmind_negalive_lr0001_g9_o1280.h5',\n",
    "               saveExp=True\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0 points \n",
      "1: 0 points \n",
      "2: 0 points \n",
      "3: 0 points \n",
      "4: 0 points \n",
      "5: 0 points \n",
      "6: 0 points \n",
      "7: 0 points \n",
      "8: 0 points \n",
      "9: 65 points \n",
      "10: 0 points \n",
      "11: 0 points \n",
      "12: 0 points \n",
      "13: 0 points \n",
      "14: 0 points \n",
      "15: 0 points \n",
      "16: 0 points \n",
      "17: 0 points \n",
      "18: 30 points \n",
      "19: 0 points \n",
      "20: 0 points \n",
      "21: 0 points \n",
      "22: 0 points \n",
      "23: 0 points \n",
      "24: 0 points \n",
      "25: 0 points \n",
      "26: 0 points \n",
      "27: 0 points \n",
      "28: 0 points \n",
      "29: 0 points \n",
      "30: 0 points \n",
      "31: 0 points \n",
      "32: 5 points \n",
      "33: 0 points \n",
      "34: 0 points \n",
      "35: 0 points \n",
      "36: 0 points \n",
      "37: 0 points \n",
      "38: 0 points \n",
      "39: 0 points \n",
      "40: 0 points \n",
      "41: 0 points \n",
      "42: 0 points \n",
      "43: 0 points \n",
      "44: 0 points \n",
      "45: 85 points \n",
      "46: 0 points \n",
      "47: 0 points \n",
      "48: 0 points \n",
      "49: 0 points \n",
      "50: 0 points \n",
      "51: 0 points \n",
      "52: 0 points \n",
      "53: 80 points \n",
      "54: 0 points \n",
      "55: 0 points \n",
      "56: 0 points \n",
      "57: 0 points \n",
      "58: 0 points \n",
      "59: 0 points \n",
      "60: 0 points \n",
      "61: 0 points \n",
      "62: 0 points \n",
      "63: 0 points \n",
      "64: 0 points \n",
      "65: 0 points \n",
      "66: 0 points \n",
      "67: 0 points \n",
      "68: 0 points \n",
      "69: 0 points \n",
      "70: 0 points \n",
      "71: 80 points \n",
      "72: 0 points \n",
      "73: 0 points \n",
      "74: 0 points \n",
      "75: 0 points \n",
      "76: 0 points \n",
      "77: 0 points \n",
      "78: 0 points \n",
      "79: 70 points \n",
      "80: 0 points \n",
      "81: 0 points \n",
      "82: 0 points \n",
      "83: 0 points \n",
      "84: 0 points \n",
      "85: 0 points \n",
      "86: 0 points \n",
      "87: 0 points \n",
      "88: 0 points \n",
      "89: 0 points \n",
      "90: 0 points \n",
      "91: 0 points \n",
      "92: 0 points \n",
      "93: 0 points \n",
      "94: 0 points \n",
      "95: 0 points \n",
      "96: 5 points \n",
      "97: 0 points \n",
      "98: 0 points \n",
      "99: 5 points \n",
      "100: 0 points \n",
      "101: 0 points \n",
      "102: 0 points \n",
      "103: 0 points \n",
      "104: 0 points \n",
      "105: 0 points \n",
      "106: 0 points \n",
      "107: 0 points \n",
      "108: 0 points \n",
      "109: 0 points \n",
      "110: 5 points \n",
      "111: 0 points \n",
      "112: 0 points \n",
      "113: 0 points \n",
      "114: 150 points \n",
      "115: 0 points \n",
      "116: 0 points \n",
      "117: 0 points \n",
      "118: 0 points \n",
      "119: 0 points \n",
      "120: 0 points \n",
      "121: 0 points \n",
      "122: 0 points \n",
      "123: 0 points \n",
      "124: 0 points \n",
      "125: 0 points \n",
      "126: 0 points \n",
      "127: 0 points \n",
      "128: 0 points \n",
      "129: 0 points \n",
      "130: 0 points \n",
      "131: 0 points \n",
      "132: 0 points \n",
      "133: 0 points \n",
      "134: 30 points \n",
      "135: 0 points \n",
      "136: 0 points \n",
      "137: 0 points \n",
      "138: 0 points \n",
      "139: 0 points \n",
      "140: 50 points \n",
      "141: 0 points \n",
      "142: 0 points \n",
      "143: 0 points \n",
      "144: 0 points \n",
      "145: 0 points \n",
      "146: 0 points \n",
      "147: 0 points \n",
      "148: 0 points \n",
      "149: 0 points \n",
      "150: 0 points \n",
      "151: 0 points \n",
      "152: 0 points \n",
      "153: 0 points \n",
      "154: 0 points \n",
      "155: 0 points \n",
      "156: 0 points \n",
      "157: 0 points \n",
      "158: 0 points \n",
      "159: 0 points \n",
      "160: 30 points \n",
      "161: 0 points \n",
      "162: 0 points \n",
      "163: 0 points \n",
      "164: 0 points \n",
      "165: 0 points \n",
      "166: 0 points \n",
      "167: 0 points \n",
      "168: 0 points \n",
      "169: 0 points \n",
      "170: 0 points \n",
      "171: 0 points \n",
      "172: 0 points \n",
      "173: 0 points \n",
      "174: 0 points \n",
      "175: 0 points \n",
      "176: 0 points \n",
      "177: 0 points \n",
      "178: 0 points \n",
      "179: 0 points \n",
      "180: 0 points \n",
      "181: 0 points \n",
      "182: 0 points \n",
      "183: 0 points \n",
      "184: 0 points \n",
      "185: 0 points \n",
      "186: 100 points \n",
      "187: 0 points \n",
      "188: 5 points \n",
      "189: 0 points \n",
      "190: 0 points \n",
      "191: 0 points \n",
      "192: 0 points \n",
      "193: 0 points \n",
      "194: 0 points \n",
      "195: 0 points \n",
      "196: 0 points \n",
      "197: 0 points \n",
      "198: 0 points \n",
      "199: 0 points \n",
      "200: 0 points \n",
      "201: 0 points \n",
      "202: 0 points \n",
      "203: 0 points \n",
      "204: 0 points \n",
      "205: 0 points \n",
      "206: 0 points \n",
      "207: 0 points \n",
      "208: 0 points \n",
      "209: 0 points \n",
      "210: 0 points \n",
      "211: 0 points \n",
      "212: 0 points \n",
      "213: 0 points \n",
      "214: 0 points \n",
      "215: 0 points \n",
      "216: 5 points \n",
      "217: 5 points \n",
      "218: 0 points \n",
      "219: 0 points \n",
      "220: 0 points \n",
      "221: 0 points \n",
      "222: 0 points \n",
      "223: 0 points \n",
      "224: 0 points \n",
      "225: 0 points \n",
      "226: 0 points \n",
      "227: 35 points \n",
      "228: 0 points \n",
      "229: 0 points \n",
      "230: 100 points \n",
      "231: 0 points \n",
      "232: 0 points \n",
      "233: 0 points \n",
      "234: 0 points \n",
      "235: 0 points \n",
      "236: 0 points \n",
      "237: 0 points \n",
      "238: 0 points \n",
      "239: 0 points \n",
      "240: 0 points \n",
      "241: 55 points \n",
      "242: 0 points \n",
      "243: 0 points \n",
      "244: 0 points \n",
      "245: 0 points \n",
      "246: 0 points \n",
      "247: 0 points \n",
      "248: 0 points \n",
      "249: 0 points \n",
      "250: 0 points \n",
      "251: 0 points \n",
      "252: 0 points \n",
      "253: 0 points \n",
      "254: 0 points \n",
      "255: 0 points \n",
      "256: 0 points \n",
      "257: 0 points \n",
      "258: 0 points \n",
      "259: 0 points \n",
      "260: 0 points \n",
      "261: 15 points \n",
      "262: 5 points \n",
      "263: 0 points \n",
      "264: 0 points \n",
      "265: 0 points \n",
      "266: 0 points \n",
      "267: 0 points \n",
      "268: 50 points \n",
      "269: 0 points \n",
      "270: 0 points \n",
      "271: 0 points \n",
      "272: 0 points \n",
      "273: 0 points \n",
      "274: 0 points \n",
      "275: 0 points \n",
      "276: 0 points \n",
      "277: 0 points \n",
      "278: 0 points \n",
      "279: 0 points \n",
      "280: 15 points \n",
      "281: 0 points \n",
      "282: 0 points \n",
      "283: 0 points \n",
      "284: 0 points \n",
      "285: 0 points \n",
      "286: 0 points \n",
      "287: 0 points \n",
      "288: 0 points \n",
      "289: 0 points \n",
      "290: 0 points \n",
      "291: 0 points \n",
      "292: 0 points \n",
      "293: 0 points \n",
      "294: 0 points \n",
      "295: 0 points \n",
      "296: 0 points \n",
      "297: 85 points \n",
      "298: 0 points \n",
      "299: 0 points \n",
      "300: 0 points \n",
      "301: 0 points \n",
      "302: 0 points \n",
      "303: 0 points \n",
      "304: 0 points \n",
      "305: 0 points \n",
      "306: 0 points \n",
      "307: 15 points \n",
      "308: 95 points \n",
      "309: 0 points \n",
      "310: 85 points \n",
      "311: 0 points \n",
      "312: 0 points \n",
      "313: 0 points \n",
      "314: 0 points \n",
      "315: 0 points \n",
      "316: 0 points \n",
      "317: 0 points \n",
      "318: 0 points \n",
      "319: 0 points \n",
      "320: 0 points \n",
      "321: 0 points \n",
      "322: 0 points \n",
      "323: 0 points \n",
      "324: 0 points \n",
      "325: 35 points \n",
      "326: 0 points \n",
      "327: 0 points \n",
      "328: 0 points \n",
      "329: 0 points \n",
      "330: 0 points \n",
      "331: 0 points \n",
      "332: 0 points \n",
      "333: 0 points \n",
      "334: 0 points \n",
      "335: 0 points \n",
      "336: 0 points \n",
      "337: 0 points \n",
      "338: 0 points \n",
      "339: 0 points \n",
      "340: 0 points \n",
      "341: 0 points \n",
      "342: 0 points \n",
      "343: 0 points \n",
      "344: 0 points \n",
      "345: 0 points \n",
      "346: 0 points \n",
      "347: 0 points \n",
      "348: 0 points \n",
      "349: 0 points \n",
      "350: 0 points \n",
      "351: 0 points \n",
      "352: 85 points \n",
      "353: 0 points \n",
      "354: 0 points \n",
      "355: 0 points \n",
      "356: 0 points \n",
      "357: 0 points \n",
      "358: 0 points \n",
      "359: 5 points \n",
      "360: 0 points \n",
      "361: 0 points \n",
      "Rando: down \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-3ed3a19cd2db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m episode = play(500,\n\u001b[1;32m----> 3\u001b[1;33m                \u001b[0msaveExp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m               )\n",
      "\u001b[1;32m<ipython-input-11-1f3ac323a0b5>\u001b[0m in \u001b[0;36mplay\u001b[1;34m(games, train, useModel, saveExp, modelFile, saveFolder, modelFunc)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m# Get current screenshot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mscreens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetScreen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# Calculate the reward for the previous move\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-516ad3c61bcf>\u001b[0m in \u001b[0;36mgetScreen\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetScreen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_screenshot_as_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget_screenshot_as_png\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_screenshot_as_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \"\"\"\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb64decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_screenshot_as_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_screenshot_as_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget_screenshot_as_base64\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_screenshot_as_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m         \"\"\"\n\u001b[1;32m-> 1062\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCREENSHOT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_window_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindowHandle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'current'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbody\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'POST'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'PUT'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m                 \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     64\u001b[0m             return self.request_encode_url(method, url, fields=fields,\n\u001b[0;32m     65\u001b[0m                                            \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                                            **urlopen_kw)\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'?'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     def request_encode_body(self, method, url, fields=None, headers=None,\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1199\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Save images\n",
    "episode = play(500,\n",
    "               saveExp=True   \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with model\n",
    "EPS_INIT = 0.0\n",
    "episode = play(1,\n",
    "               useModel=True, \n",
    "               modelFile='data/models/test.h5',\n",
    "               modelFunc=nn_model_deepmind,\n",
    "#                saveExp=True\n",
    "#                train=True\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "3000 / 3000\n",
      "  MSE = 492.64\n",
      "  Duration: 83.32 s\n",
      "Epoch 2\n",
      "3000 / 3000\n",
      "  MSE = 171.24\n",
      "  Duration: 75.45 s\n",
      "Epoch 3\n",
      "3000 / 3000\n",
      "  MSE = 102.44\n",
      "  Duration: 75.42 s\n",
      "Epoch 4\n",
      "3000 / 3000\n",
      "  MSE = 48.91\n",
      "  Duration: 79.42 s\n",
      "Epoch 5\n",
      "3000 / 3000\n",
      "  MSE = 21.04\n",
      "  Duration: 75.92 s\n",
      "Epoch 6\n",
      "3000 / 3000\n",
      "  MSE = 10.51\n",
      "  Duration: 76.82 s\n",
      "Epoch 7\n",
      "3000 / 3000\n",
      "  MSE = 5.41\n",
      "  Duration: 76.08 s\n",
      "Epoch 8\n",
      "3000 / 3000\n",
      "  MSE = 1.72\n",
      "  Duration: 79.66 s\n",
      "Epoch 9\n",
      "3000 / 3000\n",
      "  MSE = 0.83\n",
      "  Duration: 84.38 s\n",
      "Epoch 10\n",
      "3000 / 3000\n",
      "  MSE = 0.44\n",
      "  Duration: 100.99 s\n",
      "Epoch 11\n",
      "3000 / 3000\n",
      "  MSE = 0.38\n",
      "  Duration: 91.82 s\n",
      "Epoch 12\n",
      "3000 / 3000\n",
      "  MSE = 0.13\n",
      "  Duration: 99.19 s\n",
      "Epoch 13\n",
      "576 / 3000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-5674aa7713ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                               \u001b[0mload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                               file='data/models/test.h5')\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-eb8bd8e969de>\u001b[0m in \u001b[0;36mtrainModelOffline\u001b[1;34m(states, prevActions, actions, labels, nextStates, epochs, batchSize, file, load, status, modelFunc)\u001b[0m\n\u001b[0;32m    255\u001b[0m                     \u001b[0mbestNextAction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInfinity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMOVES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbestNextAction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                             \u001b[0mbestNextAction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train offline\n",
    "for i in range(1):\n",
    "#     states, prevActions, actions, labels, nextStates = readSamples(sampleFiles(3000))\n",
    "    # s2, a2, l2, n2 = readSamples(sampleFiles(50))\n",
    "    model = trainModelOffline(states, prevActions, actions, labels, nextStates,\n",
    "                              modelFunc=nn_model_deepmind,\n",
    "                              epochs=20, \n",
    "                              load=False, \n",
    "                              file='data/models/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# del states, prevActions, actions, labels, nextStates\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "s = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model structure\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "model = load_model('data/models/model.h5')\n",
    "plot_model(model, show_shapes=True, to_file='data/models/model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(episode):\n",
    "    for j, s in enumerate(e.state):\n",
    "        saveImage(s, 'data/shots2/e' + str(i) + '_c' + str(j) + '_' + moveString(e.prevAction) + '_' + moveString(e.action) + '_' + str(e.label) + '.png')\n",
    "    for j, s in enumerate(e.nextState):\n",
    "        saveImage(s, 'data/shots2/e' + str(i) + '_n' + str(j) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2, a2, l2, n2 = readSamples(sampleFiles(50))\n",
    "\n",
    "model = load_model('data/models/model_cnv3_lin_drp00_lr0001_e150_s3000_o2700.h5')\n",
    "\n",
    "for i, state in enumerate(s2):\n",
    "    saveImage(state[1], 'data/shots2/s' + str(i) + '.png')\n",
    "#     print(model.predict(np.asarray([state])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
