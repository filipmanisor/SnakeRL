{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STILL_ALIVE_REWARD = 1\n",
    "DEAD_REWARD = -1000\n",
    "\n",
    "CROP_SHAPE = (750, 539, 1)\n",
    "RESIZE_WIDTH = 180\n",
    "RESIZE_HEIGHT = 137\n",
    "READ_BATCH = 2\n",
    "\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "UP = 4\n",
    "\n",
    "SHOTS_FOLDER = 'data/shots/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectLevel(l):\n",
    "    xpath = '/html/body/section/div[2]/nav/p[' + str(l+1) + ']'\n",
    "    \n",
    "    level = browser.find_element_by_xpath(xpath)\n",
    "    level.click()\n",
    "    \n",
    "    \n",
    "def clickBoard():        \n",
    "    xpath = '/html/body/section/div[2]/div'\n",
    "    board = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "    try:\n",
    "        board.click()\n",
    "    except WebDriverException:\n",
    "        print('Exception')\n",
    "        return\n",
    "    \n",
    "    \n",
    "def getScreen(fileName):    \n",
    "    state = getState()\n",
    "#     if state == 'playing' or state == 'paused':    \n",
    "    ss = browser.get_screenshot_as_file(SHOTS_FOLDER + fileName)\n",
    "    \n",
    "    \n",
    "def getState():\n",
    "    xpath = '/html/body/section/div[2]'\n",
    "    state = browser.find_element_by_xpath(xpath)\n",
    "    c = state.get_attribute('class')\n",
    "    \n",
    "    return c.split(' ')[-1]\n",
    "\n",
    "\n",
    "def getScore():\n",
    "    state = getState()\n",
    "    \n",
    "    if state == 'playing' or state == 'paused':\n",
    "        \n",
    "        xpath = '/html/body/section/div[2]/p[1]/span'\n",
    "        score = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "        if not score.text.isnumeric():\n",
    "            return 0\n",
    "        return int(score.text)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def makeMove(m):\n",
    "    xpath = '/html/body/section/div[2]/div'\n",
    "    board = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "    if m == RIGHT:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_RIGHT)\n",
    "    elif m == DOWN:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_DOWN)\n",
    "    elif m == LEFT:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_LEFT)\n",
    "    elif m == UP:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_UP)\n",
    "        \n",
    "\n",
    "def makeRandomMove():\n",
    "    r = random.randint(0, 4)\n",
    "    makeMove(r)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastGameIndex():\n",
    "    '''Get the index of the last current game.'''\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    if len(files) == 0:\n",
    "        return 0\n",
    "    \n",
    "    last = files[-1]\n",
    "    \n",
    "    return parseName(last)[0]\n",
    "\n",
    "\n",
    "def getName(g, i, m, r):\n",
    "    '''Form the file name from the board data.'''\n",
    "    return str(g).zfill(3) + '_' + str(i).zfill(3) + '_' + str(m) + '_' + str(r) + '.png'\n",
    "\n",
    "\n",
    "def parseName(fileName):\n",
    "    '''Parse the board data from the file name.'''\n",
    "    return [int(d) for d in fileName[:-4].split('_')]\n",
    "\n",
    "\n",
    "def cropImgOld(fileName):\n",
    "    ss = plt.imread(fileName)\n",
    "\n",
    "    ss = ss[120:659, 273:1023, :]\n",
    "    \n",
    "    plt.imsave(fileName, ss)\n",
    "        \n",
    "\n",
    "def preprocImg(fileName):\n",
    "    '''Preprocess a screenshot.'''\n",
    "    im = Image.open(fileName)    \n",
    "    \n",
    "    # Crop board\n",
    "    im = im.crop((273, 120, 1023, 659))\n",
    "    \n",
    "    # Grayscale\n",
    "    im = ImageOps.grayscale(im)\n",
    "    \n",
    "    # Binarization\n",
    "    t = 127\n",
    "    im = im.point(lambda x: 255 if x > t else 0)\n",
    "    \n",
    "    # Resize\n",
    "    im = im.resize((RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "    \n",
    "    return im\n",
    "    \n",
    "    \n",
    "def preprocAll(gameIndex):\n",
    "    '''Preprocess all screenshots in the data folder.'''\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    for f in files:\n",
    "        g = parseName(f)[0]\n",
    "        \n",
    "        if g >= gameIndex:        \n",
    "            fileName =  SHOTS_FOLDER + f\n",
    "            im = preprocImg(fileName)\n",
    "            im.save(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocAll(86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://playsnake.org/'\n",
    "\n",
    "browser = webdriver.Chrome(executable_path='D:/Libraries/Drivers/chromedriver_win32/chromedriver.exe')\n",
    "# browser = webdriver.Chrome(executable_path='D:/Biblioteci/Python/chromedriver_win32/chromedriver.exe')\n",
    "browser.get(url) \n",
    "\n",
    "START_GAME = getLastGameIndex() + 1\n",
    "gameIndex = START_GAME\n",
    "\n",
    "maxGames = 100\n",
    "\n",
    "for g in range(maxGames):\n",
    "    \n",
    "    # Select the level\n",
    "    selectLevel(1)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    score = 0\n",
    "    screenIndex = 0\n",
    "    \n",
    "    clickBoard()\n",
    "    while getState() == 'playing' or getState() == 'paused':\n",
    "        s2 = getScreen('prev.png')\n",
    "        screenIndex += 1    \n",
    "\n",
    "        clickBoard()\n",
    "        m = makeRandomMove()\n",
    "        time.sleep(0.1)\n",
    "        clickBoard()\n",
    "        \n",
    "        # Update last board  \n",
    "        r = max(STILL_ALIVE_REWARD, getScore() - score) \n",
    "        fileName = getName(gameIndex, screenIndex, m, r)\n",
    "        os.rename(SHOTS_FOLDER + 'prev.png', SHOTS_FOLDER + fileName)\n",
    "        score = getScore()\n",
    "        \n",
    "    # Change reward of last board\n",
    "    g, i, m, r = parseName(fileName)\n",
    "    os.rename(SHOTS_FOLDER + fileName, SHOTS_FOLDER + getName(g, i, m, DEAD_REWARD))\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    gameIndex += 1\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "preprocAll(START_GAME)\n",
    "\n",
    "# RIGHT = 1\n",
    "# DOWN = 2\n",
    "# LEFT = 3\n",
    "# UP = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "import keras.layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "import keras.losses as losses\n",
    "from keras.backend import set_image_data_format\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    \n",
    "    labels = np.zeros(len(files))    \n",
    "    data = []\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        im = Image.open(SHOTS_FOLDER + f)\n",
    "        \n",
    "        if f in history:\n",
    "            labels[i] = history[f][2]\n",
    "        else:\n",
    "            labels[i] = STILL_ALIVE_REWARD\n",
    "            \n",
    "        data.append([np.asarray(im.convert(\"L\"))])\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def sampleData(nSamples, propD, propR, propA):\n",
    "    '''Sample the input data according to some proportions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nSamples: total number of samples\n",
    "    propD: proportion of samples which represent a death\n",
    "    propR: proportion of samples which represent a reward\n",
    "    propA: proportion of rest of samples\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    \n",
    "    perc = []\n",
    "    nd, na, nr = (0, 0, 0)\n",
    "    for f in files:\n",
    "        r = parseName(f)[3]\n",
    "        if r == DEAD_REWARD:\n",
    "            perc.append('d')\n",
    "            nd += 1\n",
    "        elif r == STILL_ALIVE_REWARD:\n",
    "            perc.append('a')\n",
    "            na += 1\n",
    "        else:\n",
    "            perc.append('r')\n",
    "            nr += 1\n",
    "        \n",
    "    n = propD * nd + propA * na + propR * nr\n",
    "    pd = propD / n\n",
    "    pa = propA / n\n",
    "    pr = propR / n\n",
    "    for i in range(len(perc)):\n",
    "        if perc[i] == 'd':\n",
    "            perc[i] = pd\n",
    "        elif perc[i] == 'a':\n",
    "            perc[i] = pa\n",
    "        else:\n",
    "            perc[i] = pr\n",
    "        \n",
    "    samples = np.random.choice(files, size=nSamples, replace=False, p=perc)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def readSamplesBasic(samples):\n",
    "    '''Read samples for basic model, which just classifies if a board is finished or not.'''\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in samples:\n",
    "        im = Image.open(SHOTS_FOLDER + file)\n",
    "        g, i, m, r = parseName(file)\n",
    "        \n",
    "        data.append([np.asarray(im.convert(\"L\"))])\n",
    "        labels.append(1 if r > 0 else 0)\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def getPreviousSample(file):\n",
    "    '''Get the name of the previous sample.'''\n",
    "    \n",
    "    g, i, m, r = parseName(file)\n",
    "    i -= 1\n",
    "    \n",
    "    if i > 0:        \n",
    "        prevFile = glob.glob(SHOTS_FOLDER + str(g).zfill(3) + '_' + str(i).zfill(3) + '*')[0]\n",
    "        prevFile = prevFile.replace('\\\\', '/')\n",
    "        prevFile = prevFile.split('/')[-1]\n",
    "#         print(prevFile)\n",
    "        return prevFile      \n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "def readSample(file):\n",
    "    '''Read a single sample as an array.'''\n",
    "    im = Image.open(SHOTS_FOLDER + file)\n",
    "    g, i, m, r = parseName(file)\n",
    "\n",
    "    data = np.asarray(im.convert(\"L\"))\n",
    "    label = 1 if r > 0 else 0\n",
    "    \n",
    "    return data, label\n",
    "    \n",
    "    \n",
    "def readSampleMove(file):\n",
    "    '''Read a single sample as an array, also returns the move.'''\n",
    "    im = Image.open(SHOTS_FOLDER + file)\n",
    "    g, i, m, r = parseName(file)\n",
    "\n",
    "    data = np.asarray(im.convert(\"L\"))\n",
    "#     if r == -1000:\n",
    "#         label = -1\n",
    "#     elif r > 1:\n",
    "#         label = r / 100\n",
    "#     else:\n",
    "#         label = 0\n",
    "    label = r\n",
    "    \n",
    "    return data, m, label\n",
    "\n",
    "\n",
    "def readBatchSamples(samples, batch):\n",
    "    '''Read samples in batches, so that we also have information about the movement.'''\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in samples:        \n",
    "        dataBatch = []\n",
    "        \n",
    "        d, label = readSample(file)\n",
    "        dataBatch.append(d)\n",
    "        \n",
    "        # Get previous files\n",
    "        prevFile = file\n",
    "        for p in range(batch - 1):\n",
    "            prevFile = getPreviousSample(prevFile)\n",
    "            \n",
    "            if prevFile == -1:\n",
    "                break\n",
    "                \n",
    "            d, _ = readSample(prevFile)\n",
    "            dataBatch.append(d)\n",
    "        \n",
    "        if prevFile != -1:\n",
    "            dataBatch.reverse()\n",
    "            data.append(dataBatch)\n",
    "            labels.append(label)\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels   \n",
    "\n",
    "\n",
    "def readBatchSamplesMove(samples, batch):\n",
    "    '''Read samples in batches, so that we also have information about the movement.\n",
    "    Also reads the moves.'''\n",
    "    data = []\n",
    "    actions = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in samples:        \n",
    "        dataBatch = []\n",
    "        \n",
    "        d, a, r = readSampleMove(file)\n",
    "        dataBatch.append(d)\n",
    "        \n",
    "        # Get previous files\n",
    "        prevFile = file\n",
    "#         print(file)\n",
    "        for p in range(batch - 1):\n",
    "            prevFile = getPreviousSample(prevFile)\n",
    "#             print('>', prevFile)\n",
    "            \n",
    "            if prevFile == -1:\n",
    "                break\n",
    "                \n",
    "            d, _ = readSample(prevFile)\n",
    "            dataBatch.append(d)\n",
    "        \n",
    "        if prevFile != -1:\n",
    "            dataBatch.reverse()\n",
    "            data.append(dataBatch)\n",
    "            actions.append(a)\n",
    "            labels.append(r)\n",
    "#             print('->', a, r)\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    actions = np.asarray(actions)\n",
    "    return data, actions, labels    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_model_full()\n",
    "data, actions, labels = readBatchSamplesMove(sampleData(1, 1, 10, 0.5), READ_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_basic():\n",
    "    '''NN model for basic test.'''\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), input_shape=(1, RESIZE_HEIGHT, RESIZE_WIDTH), activation='relu', name='conv1'))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv2'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool1'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv3'))\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv4'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool2'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv5'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool3'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten(name='flat'))\n",
    "    model.add(Dense(100, activation='relu', name='dense1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(40, activation='relu', name='dense2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = 'rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def nn_model_seq():\n",
    "    '''Sequential NN model.'''\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), input_shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), activation='relu', name='conv1'))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv2'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool1'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv3'))\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv4'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool2'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv5'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool3'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten(name='flat'))\n",
    "    model.add(Dense(100, activation='relu', name='dense1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(40, activation='relu', name='dense2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = 'rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def nn_model_full():\n",
    "    '''Full NN model, using the Keras Functional API.'''\n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv1')(screen_input)\n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv2')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool1')(conv)\n",
    "    \n",
    "    conv = Conv2D(8, (4, 4), activation='relu', name='conv3')(pool)\n",
    "    conv = Conv2D(8, (4, 4), activation='relu', name='conv4')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool2')(conv)\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv5')(pool)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(pool)\n",
    "    dense = Dense(100, activation='relu', name='dense1')(flat)\n",
    "    drop = Dropout(0.5)(dense)\n",
    "    dense = Dense(40, activation='relu', name='dense2')(drop)\n",
    "    drop = Dropout(0.5)(dense)\n",
    "    \n",
    "    action_input = Input(shape=(1,), name='action_input')\n",
    "    concat = keras.layers.concatenate([drop, action_input])\n",
    "    \n",
    "    output = Dense(1, name='output')(concat)\n",
    "    \n",
    "    model = Model(inputs=[screen_input, action_input], outputs=output)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = 'rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454, 2, 137, 180)\n",
      "454\n",
      "[0, 0, -1, 0, -1, 0, -1, -1, -1, 0, -1, -1, 0, -1, -1, 0, -1, 0, 0, 0, -1, 0, -1, -1, -1, 0, 0, 0, 0, -1, -1, 0, -1, 0, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, -1, 0, 0, 0, -1, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, -1, 0, 0, 0, -1, -1, 0, -1, 0, 0, -1, -1, -1, -1, -1, 0, 0, -1, 0, 0, 0, 0, -1, -1, 0, -1, 0, -1, 0, 0, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, -1, -1, -1, 0, -1, 0, 0, -1, -1, -1, -1, -1, 0, 0.7, -1, 0, 0, 0, -1, -1, -1, 0, -1, -1, 0, -1, 0, 0, -1, 0, -1, 0, -1, -1, 0, 0, 0, -1, 0, 0, -1, 0, -1, 0, 0, 0, 0, -1, 0.4, -1, 0, 0, 0, 0, 1.55, 0, 0, -1, -1, 0, -1, -1, -1, 0, -1, 0.6, -1, 0, -1, -1, 0, -1, -1, 0, -1, 0, 0, -1, -1, 0, -1, 0, -1, -1, 0, -1, -1, 0, -1, -1, 0, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, -1, -1, 0, 0, 0, -1, 0.8, -1, -1, 0, 0, -1, 0, 0, -1, 0, 0, -1, 0, -1, 0, -1, 0, 0, -1, -1, -1, 0, 0, 0, -1, 0, 0, -1, -1, 0.4, -1, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, -1, -1, -1, -1, -1, -1, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, -1, 0, 0, 0, -1, -1, -1, -1, 0, -1, 0, 0, 0, -1, 0, -1, 0, 0, -1, 0, 0, 0, 0, -1, 0, -1, 0, 0, -1, 0, -1, -1, -1, -1, 0, 0, 0, 0, -1, 0, -1, -1, -1, 0, -1, 0, -1, 0, 0, 0, -1, 0, -1, 0, -1, 0, -1, -1, -1, 0, -1, 0, 0, 0, -1, -1, 0, -1, 0, 0, 0, -1, 0, 0, 0, -1, 0.7, -1, -1, 0, 0, 0, 0, -1, 0, 0, -1, 0, -1, -1, -1, 0, 0, -1, 0, 0, -1, 0, -1, 0, 0, -1, -1, 0, -1, 0, 0, -1, 0, -1, -1, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0.05, 0, 0, 0, 0, 0, 0, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0]\n",
      "Epoch 1/5\n",
      "454/454 [==============================] - 74s 164ms/step - loss: 3.2475 - acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "454/454 [==============================] - 115s 254ms/step - loss: 0.8996 - acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "454/454 [==============================] - 79s 173ms/step - loss: 0.2459 - acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "454/454 [==============================] - 119s 261ms/step - loss: 1.2754 - acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "454/454 [==============================] - 100s 221ms/step - loss: 1.5648 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23fd2921c88>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic model\n",
    "# model = nn_model_basic()\n",
    "# data, labels = readSamplesBasic(sampleData(200, 10, 0.5, 0.5))\n",
    "# print(data.shape)\n",
    "# print(labels)\n",
    "# model.fit(data, labels, epochs=7, batch_size=10, shuffle=True)\n",
    "\n",
    "\n",
    "# Sequential model \n",
    "# model = nn_model_seq()\n",
    "# data, labels = readBatchSamples(sampleData(200, 10, 0.5, 0.5), READ_BATCH)\n",
    "# print(data.shape)\n",
    "# print(labels)\n",
    "# model.fit(data, labels, epochs=7, batch_size=10, shuffle=True)\n",
    "\n",
    "\n",
    "# Full model\n",
    "model = nn_model_full()\n",
    "data, actions, labels = readBatchSamplesMove(sampleData(500, 5, 5, 1), READ_BATCH)\n",
    "print(data.shape)\n",
    "print(len(actions))\n",
    "print(labels)\n",
    "labels = np.asarray(labels).reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(labels)\n",
    "labels = scaler.transform(labels)\n",
    "model.fit([data, actions], labels, epochs=5, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-212.66487]\n",
      " [-210.52394]\n",
      " [-212.94576]\n",
      " [-212.59361]\n",
      " [-213.29456]\n",
      " [-212.01389]\n",
      " [-209.86633]\n",
      " [-209.0947 ]\n",
      " [-210.29852]\n",
      " [-215.04355]\n",
      " [-211.09372]\n",
      " [-210.51903]\n",
      " [-213.66022]\n",
      " [-214.50018]\n",
      " [-209.20973]\n",
      " [-211.90112]\n",
      " [-209.58304]\n",
      " [-210.8607 ]\n",
      " [-213.99167]\n",
      " [-216.87529]]\n",
      "[[-1.14550706]\n",
      " [ 0.80082604]\n",
      " [-1.14550706]\n",
      " [ 0.80082604]\n",
      " [ 0.80082604]\n",
      " [-1.14550706]\n",
      " [-1.14550706]\n",
      " [-1.14550706]\n",
      " [-1.14550706]\n",
      " [ 0.80082604]\n",
      " [ 0.80082604]\n",
      " [ 0.80082604]\n",
      " [ 0.80082604]\n",
      " [ 0.80082604]\n",
      " [-1.14550706]\n",
      " [-1.14550706]\n",
      " [ 0.80082604]\n",
      " [-1.14550706]\n",
      " [-1.14550706]\n",
      " [-1.14550706]]\n"
     ]
    }
   ],
   "source": [
    "# model.evaluate(data[30:50], labels[30:50])\n",
    "\n",
    "print(model.predict([data[30:50], actions[30:50]]))\n",
    "print(labels[30:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 2, 137, 180)\n",
      "(193, 1)\n",
      "(193, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 193]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-c6b1f0fce75e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0msKFold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results: %.5f (%.5f)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 193]"
     ]
    }
   ],
   "source": [
    "# Build pipeline\n",
    "\n",
    "layers = []\n",
    "layers.append(('nn', KerasClassifier(build_fn=nn_model_full,\n",
    "                                   epochs=5,\n",
    "                                   batch_size=10,\n",
    "                                   verbose=1)))\n",
    "estimator = Pipeline(layers)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "data, actions, labels = readBatchSamplesMove(sampleData(200, 10, 0.5, 0.5), 2)\n",
    "\n",
    "# print(labels)\n",
    "# labels = np.asarray(labels).reshape(-1, 1)\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(labels)\n",
    "# labels = scaler.transform(labels)\n",
    "# print(labels.reshape(labels.size))\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "labels = labels.reshape((labels.size, 1))\n",
    "actions = actions.reshape((actions.size, 1))\n",
    "print(data.shape)\n",
    "print(actions.shape)\n",
    "print(labels.shape)\n",
    "     \n",
    "sKFold = StratifiedKFold(n_splits=2)\n",
    "results = cross_val_score(estimator, [data, actions], labels, cv=sKFold, verbose=1, scoring='accuracy')\n",
    "\n",
    "print(\"Results: %.5f (%.5f)\" % (results.mean(), results.std()))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
