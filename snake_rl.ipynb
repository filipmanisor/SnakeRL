{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "STILL_ALIVE_REWARD = 1\n",
    "DEAD_REWARD = -1000\n",
    "\n",
    "CROP_SHAPE = (750, 539, 1)\n",
    "RESIZE_WIDTH = 180\n",
    "RESIZE_HEIGHT = 137\n",
    "READ_BATCH = 2\n",
    "\n",
    "SHOTS_FOLDER = 'data/shots/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectLevel(l):\n",
    "    xpath = '/html/body/section/div[2]/nav/p[' + str(l+1) + ']'\n",
    "    \n",
    "    level = browser.find_element_by_xpath(xpath)\n",
    "    level.click()\n",
    "    \n",
    "    \n",
    "def clickBoard():        \n",
    "    xpath = '/html/body/section/div[2]/div'\n",
    "    board = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "    try:\n",
    "        board.click()\n",
    "    except WebDriverException:\n",
    "        print('Exception')\n",
    "        return\n",
    "    \n",
    "    \n",
    "def getScreen(fileName):    \n",
    "    state = getState()\n",
    "#     if state == 'playing' or state == 'paused':    \n",
    "    ss = browser.get_screenshot_as_file(SHOTS_FOLDER + fileName)\n",
    "    \n",
    "    \n",
    "def getState():\n",
    "    xpath = '/html/body/section/div[2]'\n",
    "    state = browser.find_element_by_xpath(xpath)\n",
    "    c = state.get_attribute('class')\n",
    "    \n",
    "    return c.split(' ')[-1]\n",
    "\n",
    "\n",
    "def getScore():\n",
    "    state = getState()\n",
    "    \n",
    "    if state == 'playing' or state == 'paused':\n",
    "        \n",
    "        xpath = '/html/body/section/div[2]/p[1]/span'\n",
    "        score = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "        if not score.text.isnumeric():\n",
    "            return 0\n",
    "        return int(score.text)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def makeMove(m):\n",
    "    xpath = '/html/body/section/div[2]/div'\n",
    "    board = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "    if m == 1:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_RIGHT)\n",
    "    elif m == 2:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_DOWN)\n",
    "    elif m == 3:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_LEFT)\n",
    "    elif m == 4:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_UP)\n",
    "        \n",
    "\n",
    "def makeRandomMove():\n",
    "    r = random.randint(0, 4)\n",
    "    makeMove(r)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastGameIndex():\n",
    "    '''Get the index of the last current game.'''\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    last = files[-1]\n",
    "    \n",
    "    return parseName(last)[0]\n",
    "\n",
    "\n",
    "def getName(g, i, m, r):\n",
    "    '''Form the file name from the board data.'''\n",
    "    return str(g).zfill(3) + '_' + str(i).zfill(3) + '_' + str(m) + '_' + str(r) + '.png'\n",
    "\n",
    "\n",
    "def parseName(fileName):\n",
    "    '''Parse the board data from the file name.'''\n",
    "    return [int(d) for d in fileName[:-4].split('_')]\n",
    "\n",
    "\n",
    "def cropImgOld(fileName):\n",
    "    ss = plt.imread(fileName)\n",
    "\n",
    "    ss = ss[120:659, 273:1023, :]\n",
    "    \n",
    "    plt.imsave(fileName, ss)\n",
    "        \n",
    "\n",
    "def preprocImg(fileName):\n",
    "    '''Preprocess a screenshot.'''\n",
    "    im = Image.open(fileName)    \n",
    "    \n",
    "    # Crop board\n",
    "    im = im.crop((273, 120, 1023, 659))\n",
    "    \n",
    "    # Grayscale\n",
    "    im = ImageOps.grayscale(im)\n",
    "    \n",
    "    # Binarization\n",
    "    t = 127\n",
    "    im = im.point(lambda x: 255 if x > t else 0)\n",
    "    \n",
    "    # Resize\n",
    "    im = im.resize((RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "    \n",
    "    return im\n",
    "    \n",
    "    \n",
    "def preprocAll(gameIndex):\n",
    "    '''Preprocess all screenshots in the data folder.'''\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    for f in files:\n",
    "        g = parseName(f)[0]\n",
    "        \n",
    "        if g >= gameIndex:        \n",
    "            fileName =  SHOTS_FOLDER + f\n",
    "            im = preprocImg(fileName)\n",
    "            im.save(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocAll(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://playsnake.org/'\n",
    "\n",
    "browser = webdriver.Chrome(executable_path='D:/Libraries/Drivers/chromedriver_win32/chromedriver.exe')\n",
    "# browser = webdriver.Chrome(executable_path='D:/Biblioteci/Python/chromedriver_win32/chromedriver.exe')\n",
    "browser.get(url) \n",
    "\n",
    "START_GAME = getLastGameIndex() + 1\n",
    "gameIndex = START_GAME\n",
    "\n",
    "maxGames = 2\n",
    "\n",
    "for g in range(maxGames):\n",
    "    \n",
    "    # Select the level\n",
    "    selectLevel(1)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    score = 0\n",
    "    screenIndex = 0\n",
    "    \n",
    "    clickBoard()\n",
    "    while getState() == 'playing' or getState() == 'paused':\n",
    "        s2 = getScreen('prev.png')\n",
    "        screenIndex += 1    \n",
    "\n",
    "        clickBoard()\n",
    "        m = makeRandomMove()\n",
    "        clickBoard()\n",
    "        \n",
    "        # Update last board  \n",
    "        r = max(STILL_ALIVE_REWARD, getScore() - score) \n",
    "        fileName = getName(gameIndex, screenIndex, m, r)\n",
    "        os.rename(SHOTS_FOLDER + 'prev.png', SHOTS_FOLDER + fileName)\n",
    "        score = getScore()\n",
    "        \n",
    "    # Change reward of last board\n",
    "    g, i, m, r = parseName(fileName)\n",
    "    os.rename(SHOTS_FOLDER + fileName, SHOTS_FOLDER + getName(g, i, m, DEAD_REWARD))\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    gameIndex += 1\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "preprocAll(START_GAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "import keras.losses as losses\n",
    "from keras.backend import set_image_data_format\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    \n",
    "    labels = np.zeros(len(files))    \n",
    "    data = []\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        im = Image.open(SHOTS_FOLDER + f)\n",
    "        \n",
    "        if f in history:\n",
    "            labels[i] = history[f][2]\n",
    "        else:\n",
    "            labels[i] = STILL_ALIVE_REWARD\n",
    "            \n",
    "        data.append([np.asarray(im.convert(\"L\"))])\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def sampleData(nSamples, propD, propR, propA):\n",
    "    '''Sample the input data according to some proportions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nSamples: total number of samples\n",
    "    propD: proportion of samples which represent a death\n",
    "    propR: proportion of samples which represent a reward\n",
    "    propA: proportion of rest of samples\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    \n",
    "    perc = []\n",
    "    nd, na, nr = (0, 0, 0)\n",
    "    for f in files:\n",
    "        r = parseName(f)[3]\n",
    "        if r == DEAD_REWARD:\n",
    "            perc.append('d')\n",
    "            nd += 1\n",
    "        elif r == STILL_ALIVE_REWARD:\n",
    "            perc.append('a')\n",
    "            na += 1\n",
    "        else:\n",
    "            perc.append('r')\n",
    "            nr += 1\n",
    "        \n",
    "    n = propD * nd + propA * na + propR * nr\n",
    "    pd = propD / n\n",
    "    pa = propA / n\n",
    "    pr = propR / n\n",
    "    for i in range(len(perc)):\n",
    "        if perc[i] == 'd':\n",
    "            perc[i] = pd\n",
    "        elif perc[i] == 'a':\n",
    "            perc[i] = pa\n",
    "        else:\n",
    "            perc[i] = pr\n",
    "        \n",
    "    samples = np.random.choice(files, size=nSamples, replace=False, p=perc)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def readSamplesBasic(samples):\n",
    "    '''Read samples for basic model, which just classifies if a board is finished or not.'''\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in samples:\n",
    "        im = Image.open(SHOTS_FOLDER + file)\n",
    "        g, i, m, r = parseName(file)\n",
    "        \n",
    "        data.append([np.asarray(im.convert(\"L\"))])\n",
    "        labels.append(1 if r > 0 else 0)\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def getPreviousSample(file):\n",
    "    '''Get the name of the previous sample.'''\n",
    "    \n",
    "    g, i, m, r = parseName(file)\n",
    "    i -= 1\n",
    "    \n",
    "    if i > 0:        \n",
    "        prevFile = glob.glob(SHOTS_FOLDER + str(g).zfill(3) + '_' + str(i).zfill(3) + '*')[0]\n",
    "        prevFile = prevFile.replace('\\\\', '/')\n",
    "        prevFile = prevFile.split('/')[-1]\n",
    "#         print(prevFile)\n",
    "        return prevFile      \n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "def readSample(file):\n",
    "    '''Read a single sample as an array.'''\n",
    "    im = Image.open(SHOTS_FOLDER + file)\n",
    "    g, i, m, r = parseName(file)\n",
    "\n",
    "    data = np.asarray(im.convert(\"L\"))\n",
    "    label = 1 if r > 0 else 0\n",
    "    \n",
    "    return data, label\n",
    "\n",
    "def readBatchSamples(samples, batch):\n",
    "    '''Read samples in batches, so that we also have information about the movement.'''\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in samples:        \n",
    "        dataBatch = []\n",
    "        \n",
    "        d, label = readSample(file)\n",
    "        dataBatch.append(d)\n",
    "        \n",
    "        # Get previous files\n",
    "        prevFile = file\n",
    "        for p in range(batch - 1):\n",
    "            prevFile = getPreviousSample(prevFile)\n",
    "            \n",
    "            if prevFile == -1:\n",
    "                break\n",
    "                \n",
    "            d, _ = readSample(prevFile)\n",
    "            dataBatch.append(d)\n",
    "        \n",
    "        if prevFile != -1:\n",
    "            dataBatch.reverse()\n",
    "            data.append(dataBatch)\n",
    "            labels.append(label)\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "024_041_3_-1000.png\n",
      " 024_040_4_1.png\n",
      "010_023_0_1.png\n",
      " 010_022_4_1.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[  0,   0,   0, ...,   0,   0,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          ...,\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0,   0,   0, ...,   0,   0,   0]],\n",
       " \n",
       "         [[  0,   0,   0, ...,   0,   0,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          ...,\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0,   0,   0, ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "        [[[  0,   0,   0, ...,   0,   0,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          ...,\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0,   0,   0, ...,   0,   0,   0]],\n",
       " \n",
       "         [[  0,   0,   0, ...,   0,   0,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          ...,\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0, 255, 255, ..., 255, 255,   0],\n",
       "          [  0,   0,   0, ...,   0,   0,   0]]]], dtype=uint8), [0, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '001_033_0_1.png'\n",
    "\n",
    "getPreviousSample(file)\n",
    "\n",
    "readBatchSamples(sampleData(2, 10, 0.5, 0.5), READ_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_basic():\n",
    "    '''NN model for basic test.'''\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), input_shape=(1, RESIZE_HEIGHT, RESIZE_WIDTH), activation='relu', name='conv1'))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv2'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool1'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv3'))\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv4'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool2'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv5'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool3'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten(name='flat'))\n",
    "    model.add(Dense(100, activation='relu', name='dense1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(40, activation='relu', name='dense2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = 'rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), input_shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), activation='relu', name='conv1'))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv2'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool1'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv3'))\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv4'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool2'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv5'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool3'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten(name='flat'))\n",
    "    model.add(Dense(100, activation='relu', name='dense1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(40, activation='relu', name='dense2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = 'rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 2, 137, 180)\n",
      "[0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Epoch 1/7\n",
      "192/192 [==============================] - 35s 183ms/step - loss: 6.0473 - acc: 0.5365\n",
      "Epoch 2/7\n",
      "192/192 [==============================] - 32s 164ms/step - loss: 1.4074 - acc: 0.6042\n",
      "Epoch 3/7\n",
      "192/192 [==============================] - 33s 173ms/step - loss: 0.6044 - acc: 0.6667\n",
      "Epoch 4/7\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.5321 - acc: 0.6927\n",
      "Epoch 5/7\n",
      "192/192 [==============================] - 42s 221ms/step - loss: 0.4231 - acc: 0.7917\n",
      "Epoch 6/7\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.3594 - acc: 0.8385\n",
      "Epoch 7/7\n",
      "160/192 [========================>.....] - ETA: 7s - loss: 0.2844 - acc: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-f93f3f51de6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msampleData\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = nn_model_basic()\n",
    "\n",
    "# data, labels = readSamplesBasic(sampleData(200, 10, 0.5, 0.5))\n",
    "# print(data.shape)\n",
    "# print(labels)\n",
    "\n",
    "# sampleData\n",
    "\n",
    "# model.fit(data, labels, epochs=7, batch_size=10, shuffle=True)\n",
    "\n",
    "model = nn_model()\n",
    "\n",
    "data, labels = readBatchSamples(sampleData(200, 10, 0.5, 0.5), READ_BATCH)\n",
    "print(data.shape)\n",
    "print(labels)\n",
    "\n",
    "sampleData\n",
    "\n",
    "model.fit(data, labels, epochs=7, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37177   ]\n",
      " [0.3842014 ]\n",
      " [0.9943773 ]\n",
      " [0.99995625]\n",
      " [0.19080411]\n",
      " [0.72264636]\n",
      " [0.99999833]\n",
      " [0.3791355 ]\n",
      " [0.15641795]\n",
      " [0.99997747]\n",
      " [0.9999697 ]\n",
      " [0.08497947]\n",
      " [0.4736045 ]\n",
      " [0.26582742]\n",
      " [0.9999912 ]\n",
      " [0.31341767]\n",
      " [0.9981779 ]\n",
      " [0.99997973]\n",
      " [0.15890193]\n",
      " [0.05796547]]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# model.evaluate(data[30:50], labels[30:50])\n",
    "\n",
    "print(model.predict(data[30:50]))\n",
    "print(labels[30:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "129/129 [==============================] - 23s 179ms/step - loss: 2.1703 - acc: 0.5504\n",
      "Epoch 2/5\n",
      "129/129 [==============================] - 21s 164ms/step - loss: 0.6090 - acc: 0.6589\n",
      "Epoch 3/5\n",
      "129/129 [==============================] - 20s 158ms/step - loss: 0.4825 - acc: 0.6512\n",
      "Epoch 4/5\n",
      "129/129 [==============================] - 23s 179ms/step - loss: 0.4400 - acc: 0.7752\n",
      "Epoch 5/5\n",
      "129/129 [==============================] - 22s 170ms/step - loss: 0.3797 - acc: 0.8295\n",
      "65/65 [==============================] - 5s 74ms/step\n",
      "Epoch 1/5\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 6.3558 - acc: 0.5194\n",
      "Epoch 2/5\n",
      "129/129 [==============================] - 20s 152ms/step - loss: 0.6803 - acc: 0.6124\n",
      "Epoch 3/5\n",
      "129/129 [==============================] - 27s 206ms/step - loss: 0.4767 - acc: 0.6822\n",
      "Epoch 4/5\n",
      "129/129 [==============================] - 23s 181ms/step - loss: 0.4631 - acc: 0.7752\n",
      "Epoch 5/5\n",
      "129/129 [==============================] - 26s 199ms/step - loss: 0.3660 - acc: 0.7907\n",
      "65/65 [==============================] - 7s 101ms/step\n",
      "Epoch 1/5\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 10.2921 - acc: 0.3615\n",
      "Epoch 2/5\n",
      "130/130 [==============================] - 26s 201ms/step - loss: 10.4134 - acc: 0.3538\n",
      "Epoch 3/5\n",
      "130/130 [==============================] - 28s 216ms/step - loss: 10.0388 - acc: 0.3769\n",
      "Epoch 4/5\n",
      "130/130 [==============================] - 26s 203ms/step - loss: 10.5374 - acc: 0.3462\n",
      "Epoch 5/5\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 10.7808 - acc: 0.3308\n",
      "64/64 [==============================] - 5s 82ms/step\n",
      "Results: 0.59151 (0.17530)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Build pipeline\n",
    "\n",
    "layers = []\n",
    "layers.append(('nn', KerasClassifier(build_fn=nn_model,\n",
    "                                   epochs=5,\n",
    "                                   batch_size=10,\n",
    "                                   verbose=1)))\n",
    "estimator = Pipeline(layers)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "data, labels = readBatchSamples(sampleData(200, 10, 0.5, 0.5), 2)\n",
    "\n",
    "sKFold = StratifiedKFold(n_splits=3)\n",
    "results = cross_val_score(estimator, data, labels, cv=sKFold, verbose=1, scoring='accuracy')\n",
    "\n",
    "print(\"Results: %.5f (%.5f)\" % (results.mean(), results.std()))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
