{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STILL_ALIVE_REWARD = 1\n",
    "DEAD_REWARD = -1000\n",
    "\n",
    "CROP_SHAPE = (750, 539, 1)\n",
    "RESIZE_WIDTH = 180\n",
    "RESIZE_HEIGHT = 137\n",
    "READ_BATCH = 2\n",
    "\n",
    "MOVES = 5\n",
    "NONE = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "UP = 4\n",
    "\n",
    "SHOTS_FOLDER = 'data/shots/'\n",
    "\n",
    "GAMMA = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectLevel(l):\n",
    "    xpath = '/html/body/section/div[2]/nav/p[' + str(l+1) + ']'\n",
    "    \n",
    "    level = browser.find_element_by_xpath(xpath)\n",
    "    level.click()\n",
    "    \n",
    "    \n",
    "def clickBoard():        \n",
    "    xpath = '/html/body/section/div[2]/div'\n",
    "    board = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "    try:\n",
    "        board.click()\n",
    "    except WebDriverException:\n",
    "        print('Exception')\n",
    "        return\n",
    "    \n",
    "    \n",
    "def saveScreen(fileName):    \n",
    "    state = getState()\n",
    "#     if state == 'playing' or state == 'paused':    \n",
    "    ss = browser.get_screenshot_as_file(SHOTS_FOLDER + fileName)\n",
    "    \n",
    "    \n",
    "def getScreen():\n",
    "    ss = browser.get_screenshot_as_png()\n",
    "    im = Image.open(io.BytesIO(ss))\n",
    "    \n",
    "    im = preprocImg(im)\n",
    "    return np.asarray(im.convert(\"L\"))\n",
    "    \n",
    "    \n",
    "def getState():\n",
    "    xpath = '/html/body/section/div[2]'\n",
    "    state = browser.find_element_by_xpath(xpath)\n",
    "    c = state.get_attribute('class')\n",
    "    \n",
    "    return c.split(' ')[-1]\n",
    "\n",
    "\n",
    "def getScore():\n",
    "    state = getState()\n",
    "    \n",
    "    if state == 'playing' or state == 'paused':\n",
    "        \n",
    "        xpath = '/html/body/section/div[2]/p[1]/span'\n",
    "        score = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "        if not score.text.isnumeric():\n",
    "            return 0\n",
    "        return int(score.text)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def makeMove(m):\n",
    "    xpath = '/html/body/section/div[2]/div'\n",
    "    board = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "    if m == RIGHT:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_RIGHT)\n",
    "    elif m == DOWN:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_DOWN)\n",
    "    elif m == LEFT:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_LEFT)\n",
    "    elif m == UP:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_UP)\n",
    "        \n",
    "\n",
    "def makeRandomMove():\n",
    "    r = random.randint(0, 4)\n",
    "    makeMove(r)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastGameIndex():\n",
    "    '''Get the index of the last current game.'''\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    if len(files) == 0:\n",
    "        return 0\n",
    "    \n",
    "    last = files[-1]\n",
    "    \n",
    "    return parseName(last)[0]\n",
    "\n",
    "\n",
    "def getName(g, i, m, r):\n",
    "    '''Form the file name from the board data.'''\n",
    "    return str(g).zfill(3) + '_' + str(i).zfill(3) + '_' + str(m) + '_' + str(r) + '.png'\n",
    "\n",
    "\n",
    "def parseName(fileName):\n",
    "    '''Parse the board data from the file name.'''\n",
    "    return [int(d) for d in fileName[:-4].split('_')]\n",
    "\n",
    "\n",
    "def cropImgOld(fileName):\n",
    "    ss = plt.imread(fileName)\n",
    "\n",
    "    ss = ss[120:659, 273:1023, :]\n",
    "    \n",
    "    plt.imsave(fileName, ss)\n",
    "        \n",
    "\n",
    "def preprocImg(im):\n",
    "    '''Preprocess a screenshot.'''     \n",
    "    # Crop board\n",
    "    im = im.crop((273, 120, 1023, 659))\n",
    "    \n",
    "    # Grayscale\n",
    "    im = ImageOps.grayscale(im)\n",
    "    \n",
    "    # Binarization\n",
    "    t = 127\n",
    "    im = im.point(lambda x: 255 if x > t else 0)\n",
    "    \n",
    "    # Resize\n",
    "    im = im.resize((RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "    \n",
    "    return im\n",
    "    \n",
    "    \n",
    "def preprocAll(gameIndex):\n",
    "    '''Preprocess all screenshots in the data folder.'''\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    for f in files:\n",
    "        g = parseName(f)[0]\n",
    "        \n",
    "        if g >= gameIndex:        \n",
    "            fileName =  SHOTS_FOLDER + f\n",
    "            im = Image.open(fileName)   \n",
    "            im = preprocImg(im)\n",
    "            im.save(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocAll(86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://playsnake.org/'\n",
    "\n",
    "browser = webdriver.Chrome(executable_path='D:/Libraries/Drivers/chromedriver_win32/chromedriver.exe')\n",
    "# browser = webdriver.Chrome(executable_path='D:/Biblioteci/Python/chromedriver_win32/chromedriver.exe')\n",
    "browser.get(url) \n",
    "\n",
    "START_GAME = getLastGameIndex() + 1\n",
    "gameIndex = START_GAME\n",
    "\n",
    "maxGames = 100\n",
    "\n",
    "for g in range(maxGames):\n",
    "    \n",
    "    # Select the level\n",
    "    selectLevel(1)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    score = 0\n",
    "    screenIndex = 0\n",
    "    \n",
    "    clickBoard()\n",
    "    while getState() == 'playing' or getState() == 'paused':\n",
    "        saveScreen('prev.png')\n",
    "        screenIndex += 1    \n",
    "\n",
    "        clickBoard()\n",
    "        m = makeRandomMove()\n",
    "        time.sleep(0.1)\n",
    "        clickBoard()\n",
    "        \n",
    "        # Update last board  \n",
    "        r = max(STILL_ALIVE_REWARD, getScore() - score) \n",
    "        fileName = getName(gameIndex, screenIndex, m, r)\n",
    "        os.rename(SHOTS_FOLDER + 'prev.png', SHOTS_FOLDER + fileName)\n",
    "        score = getScore()\n",
    "        \n",
    "    # Change reward of last board\n",
    "    g, i, m, r = parseName(fileName)\n",
    "    os.rename(SHOTS_FOLDER + fileName, SHOTS_FOLDER + getName(g, i, m, DEAD_REWARD))\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    gameIndex += 1\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "preprocAll(START_GAME)\n",
    "\n",
    "# RIGHT = 1\n",
    "# DOWN = 2\n",
    "# LEFT = 3\n",
    "# UP = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "import keras.layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "import keras.losses as losses\n",
    "from keras.models import load_model\n",
    "from keras.backend import set_image_data_format\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    \n",
    "    labels = np.zeros(len(files))    \n",
    "    data = []\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        im = Image.open(SHOTS_FOLDER + f)\n",
    "        \n",
    "        if f in history:\n",
    "            labels[i] = history[f][2]\n",
    "        else:\n",
    "            labels[i] = STILL_ALIVE_REWARD\n",
    "            \n",
    "        data.append([np.asarray(im.convert(\"L\"))])\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def sampleData(nSamples, propD, propR, propA):\n",
    "    '''Sample the input data according to some proportions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nSamples: total number of samples\n",
    "    propD: proportion of samples which represent a death\n",
    "    propR: proportion of samples which represent a reward\n",
    "    propA: proportion of rest of samples\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    \n",
    "    perc = []\n",
    "    nd, na, nr = (0, 0, 0)\n",
    "    for f in files:\n",
    "        r = parseName(f)[3]\n",
    "        if r == DEAD_REWARD:\n",
    "            perc.append('d')\n",
    "            nd += 1\n",
    "        elif r == STILL_ALIVE_REWARD:\n",
    "            perc.append('a')\n",
    "            na += 1\n",
    "        else:\n",
    "            perc.append('r')\n",
    "            nr += 1\n",
    "        \n",
    "    n = propD * nd + propA * na + propR * nr\n",
    "    pd = propD / n\n",
    "    pa = propA / n\n",
    "    pr = propR / n\n",
    "    for i in range(len(perc)):\n",
    "        if perc[i] == 'd':\n",
    "            perc[i] = pd\n",
    "        elif perc[i] == 'a':\n",
    "            perc[i] = pa\n",
    "        else:\n",
    "            perc[i] = pr\n",
    "        \n",
    "    samples = np.random.choice(files, size=nSamples, replace=False, p=perc)\n",
    "    print('Sampled data.')\n",
    "    return samples\n",
    "\n",
    "\n",
    "def readSamplesBasic(samples):\n",
    "    '''Read samples for basic model, which just classifies if a board is finished or not.'''\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in samples:\n",
    "        im = Image.open(SHOTS_FOLDER + file)\n",
    "        g, i, m, r = parseName(file)\n",
    "        \n",
    "        data.append([np.asarray(im.convert(\"L\"))])\n",
    "        labels.append(1 if r > 0 else 0)\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def getPreviousSample(file):\n",
    "    '''Get the name of the previous sample.'''\n",
    "    \n",
    "    g, i, m, r = parseName(file)\n",
    "    i -= 1\n",
    "    \n",
    "    if i > 0:        \n",
    "        prevFile = glob.glob(SHOTS_FOLDER + str(g).zfill(3) + '_' + str(i).zfill(3) + '*')[0]\n",
    "        prevFile = prevFile.replace('\\\\', '/')\n",
    "        prevFile = prevFile.split('/')[-1]\n",
    "        return prevFile      \n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def getNextSample(file):\n",
    "    '''Get the name of the next sample.'''\n",
    "    \n",
    "    g, i, m, r = parseName(file)\n",
    "    i += 1\n",
    "    \n",
    "    prevFile = glob.glob(SHOTS_FOLDER + str(g).zfill(3) + '_' + str(i).zfill(3) + '*')\n",
    "    if len(prevFile) == 1:\n",
    "        prevFile = prevFile[0]\n",
    "        prevFile = prevFile.replace('\\\\', '/')\n",
    "        prevFile = prevFile.split('/')[-1]\n",
    "        return prevFile\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "def readSample(file):\n",
    "    '''Read a single sample as an array.'''\n",
    "    im = Image.open(SHOTS_FOLDER + file)\n",
    "    g, i, m, r = parseName(file)\n",
    "\n",
    "    data = np.asarray(im.convert(\"L\"))\n",
    "    label = 1 if r > 0 else 0\n",
    "    \n",
    "    return data, label\n",
    "    \n",
    "    \n",
    "def readSampleMove(file):\n",
    "    '''Read a single sample as an array, also returns the move.'''\n",
    "    im = Image.open(SHOTS_FOLDER + file)\n",
    "    g, i, m, r = parseName(file)\n",
    "\n",
    "    data = np.asarray(im.convert(\"L\"))\n",
    "    if r == -1000:\n",
    "        label = -1\n",
    "    elif r > 1:\n",
    "        label = r / 100\n",
    "    else:\n",
    "        label = 0\n",
    "#     label = r\n",
    "    \n",
    "    return data, m, label\n",
    "\n",
    "\n",
    "def readBatchSamples(samples, batch):\n",
    "    '''Read samples in batches, so that we also have information about the movement.'''\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in samples:        \n",
    "        dataBatch = []\n",
    "        \n",
    "        d, label = readSample(file)\n",
    "        dataBatch.append(d)\n",
    "        \n",
    "        # Get previous files\n",
    "        prevFile = file\n",
    "        for p in range(batch - 1):\n",
    "            prevFile = getPreviousSample(prevFile)\n",
    "            \n",
    "            if prevFile == -1:\n",
    "                break\n",
    "                \n",
    "            d, _ = readSample(prevFile)\n",
    "            dataBatch.append(d)\n",
    "        \n",
    "        if prevFile != -1:\n",
    "            dataBatch.reverse()\n",
    "            data.append(dataBatch)\n",
    "            labels.append(label)\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    return data, labels   \n",
    "\n",
    "\n",
    "def getStateBatches(file, batch):\n",
    "    '''Get the image batches for the current and next state.'''\n",
    "          \n",
    "    s, _, _ = readSampleMove(file)\n",
    "    \n",
    "    # Get the image batch for the current state\n",
    "    curBatch = []\n",
    "    curBatch.append(s)\n",
    "    \n",
    "    # Get previous files\n",
    "    prevFile = file\n",
    "    for p in range(batch - 1):\n",
    "        prevFile = getPreviousSample(prevFile)\n",
    "        \n",
    "        if prevFile == -1:\n",
    "            break\n",
    "            \n",
    "        s, _ = readSample(prevFile)\n",
    "        curBatch.append(s)\n",
    "        \n",
    "    if prevFile == -1:\n",
    "        return -1, -1\n",
    "    else:\n",
    "        #Get the image batch for the next state\n",
    "        nextBatch = []\n",
    "        \n",
    "        nextFile = getNextSample(file)\n",
    "        if nextFile == -1:\n",
    "            curBatch.reverse()\n",
    "            return curBatch, curBatch\n",
    "        \n",
    "        nextState, _ = readSample(nextFile)        \n",
    "        \n",
    "        nextBatch.append(nextState)        \n",
    "        nextBatch.extend(curBatch[:-1])\n",
    "        \n",
    "        curBatch.reverse()\n",
    "        nextBatch.reverse()\n",
    "        return curBatch, nextBatch\n",
    "\n",
    "\n",
    "def readBatchSamplesMove(samples, batch):\n",
    "    '''Read samples in batches, so that we also have information about the movement.\n",
    "    Also reads the moves.'''\n",
    "    states = []\n",
    "    actions = []\n",
    "    labels = []\n",
    "    nextStates = []\n",
    "    \n",
    "    for i, file in enumerate(samples):          \n",
    "        _, a, r = readSampleMove(file)\n",
    "        \n",
    "        curBatch, nextBatch = getStateBatches(file, batch)\n",
    "        if curBatch != -1:\n",
    "            states.append(curBatch)\n",
    "            actions.append(a)\n",
    "            labels.append(r)\n",
    "            nextStates.append(nextBatch)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "    states = np.asarray(states)\n",
    "    actions = np.asarray(actions)\n",
    "    nextStates = np.asarray(nextStates)\n",
    "    labels = np.asarray(labels)\n",
    "       \n",
    "    # Scale labels\n",
    "#     labels = np.asarray(labels).reshape(-1, 1)\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(labels)\n",
    "#     labels = scaler.transform(labels)\n",
    "    \n",
    "    return states, actions, labels, nextStates    \n",
    "    \n",
    "    \n",
    "def getModelMoveInput(model, screens):\n",
    "    '''Get the move from the model which takes moves as input.'''\n",
    "    \n",
    "    m = 0\n",
    "    bestMove = 0\n",
    "    bestScore = DEAD_REWARD - 1\n",
    "    \n",
    "    while m < MOVES:\n",
    "        score = model.predict([np.asarray([screens]), np.asarray([m])])      \n",
    "        \n",
    "        print(m, score)\n",
    "        if score > bestScore:\n",
    "            bestScore = score\n",
    "            bestMove = m\n",
    "            \n",
    "        m += 1        \n",
    "    \n",
    "    \n",
    "def getModelMoveOutput(model, screens):\n",
    "    '''Get the move from the model which produces move scores as outputs.'''\n",
    "    res = model.predict(np.asarray([screens]))\n",
    "    m = np.argmax(res)\n",
    "    \n",
    "    return m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getModelMoveOutput(model, states[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN basic\n",
    "\n",
    "Sequential, citeste doar o imagine, nu considera actiunea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_basic():\n",
    "    '''NN model for basic test.'''\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), input_shape=(1, RESIZE_HEIGHT, RESIZE_WIDTH), activation='relu', name='conv1'))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv2'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool1'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv3'))\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv4'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool2'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv5'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool3'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten(name='flat'))\n",
    "    model.add(Dense(100, activation='relu', name='dense1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(40, activation='relu', name='dense2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = 'rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data.\n",
      "(200, 1, 137, 180)\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "Epoch 1/7\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 1.7263 - acc: 0.5800\n",
      "Epoch 2/7\n",
      "200/200 [==============================] - 47s 233ms/step - loss: 0.7055 - acc: 0.7150\n",
      "Epoch 3/7\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.6292 - acc: 0.7800\n",
      "Epoch 4/7\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 0.6353 - acc: 0.7750\n",
      "Epoch 5/7\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.4249 - acc: 0.8150\n",
      "Epoch 6/7\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 0.4401 - acc: 0.8450\n",
      "Epoch 7/7\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.3498 - acc: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8069e0b00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn_model_basic()\n",
    "data, labels = readSamplesBasic(sampleData(200, 10, 0.5, 0.5))\n",
    "print(data.shape)\n",
    "print(labels)\n",
    "\n",
    "model.fit(data, labels, epochs=7, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN seq\n",
    "\n",
    "Sequential, citeste batch-uri de imagini, dar nu considera si actiunea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_seq():\n",
    "    '''Sequential NN model.'''\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), input_shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), activation='relu', name='conv1'))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv2'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool1'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv3'))\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', name='conv4'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool2'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', name='conv5'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), name='pool3'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten(name='flat'))\n",
    "    model.add(Dense(100, activation='relu', name='dense1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(40, activation='relu', name='dense2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = 'rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_model_seq()\n",
    "data, labels = readBatchSamples(sampleData(200, 10, 0.5, 0.5), READ_BATCH)\n",
    "print(data.shape)\n",
    "print(labels)\n",
    "\n",
    "model.fit(data, labels, epochs=7, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN action input\n",
    "\n",
    "Functional API, citeste batch-uri de imagini, considera actiunea ca un input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nn_model_actionlast():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Action as input, added before the final layer.'''\n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv1')(screen_input)\n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv2')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool1')(conv)\n",
    "    \n",
    "    conv = Conv2D(8, (4, 4), activation='relu', name='conv3')(pool)\n",
    "    conv = Conv2D(8, (4, 4), activation='relu', name='conv4')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool2')(conv)\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv5')(pool)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(pool)\n",
    "    dense = Dense(100, activation='relu', name='dense1')(flat)\n",
    "    drop = Dropout(0.5)(dense)\n",
    "    dense = Dense(40, activation='relu', name='dense2')(drop)\n",
    "    drop = Dropout(0.5)(dense)\n",
    "    \n",
    "    action_input = Input(shape=(1,), name='action_input')\n",
    "    concat = keras.layers.concatenate([drop, action_input])\n",
    "    \n",
    "    output = Dense(1, activation='linear', name='output')(concat)\n",
    "    \n",
    "    model = Model(inputs=[screen_input, action_input], outputs=output)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def nn_model_actionmid():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Action as input, added after convolutional layers.'''\n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv1')(screen_input)\n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv2')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool1')(conv)\n",
    "    \n",
    "    conv = Conv2D(8, (4, 4), activation='relu', name='conv3')(pool)\n",
    "    conv = Conv2D(8, (4, 4), activation='relu', name='conv4')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool2')(conv)\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv5')(pool)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(pool)\n",
    "    \n",
    "    action_input = Input(shape=(1,), name='action_input')\n",
    "    concat = keras.layers.concatenate([flat, action_input])\n",
    "    \n",
    "    dense = Dense(100, activation='relu', name='dense1')(concat)\n",
    "    drop = Dropout(0.5)(dense)\n",
    "    dense = Dense(40, activation='relu', name='dense2')(dense)\n",
    "    drop = Dropout(0.5)(dense)\n",
    "        \n",
    "    output = Dense(1, activation='linear', name='output')(dense)\n",
    "    \n",
    "    model = Model(inputs=[screen_input, action_input], outputs=output)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data.\n",
      "0\n",
      "100\n",
      "(200, 1, 137, 180)\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 27s 140ms/step - loss: 43.5866 - acc: 0.1737\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 33s 172ms/step - loss: 1.7800 - acc: 0.2789\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 34s 180ms/step - loss: 1.1783 - acc: 0.3263\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 44s 230ms/step - loss: 1.0411 - acc: 0.3842\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 28s 148ms/step - loss: 0.9120 - acc: 0.3579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d80a2b16d8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn_model_actionlast()\n",
    "states, actions, labels, nextStates = readBatchSamplesMove(sampleData(200, 5, 5, 1), READ_BATCH)\n",
    "print(data.shape)\n",
    "\n",
    "# labels = np.asarray(labels).reshape(-1, 1)\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(labels)\n",
    "# labels = scaler.transform(labels)\n",
    "# print(labels)\n",
    "\n",
    "model.fit([states, actions], labels, epochs=5, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN action output\n",
    "\n",
    "Functional API, citeste batch-uri de imagini, considera actiunea ca output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nn_model_actionoutput():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Action as output, final layer has as many neurons as possible actions.'''\n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv1')(screen_input)\n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv2')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool1')(conv)\n",
    "    \n",
    "    conv = Conv2D(8, (4, 4), activation='relu', name='conv3')(pool)\n",
    "    conv = Conv2D(8, (4, 4), activation='relu', name='conv4')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool2')(conv)\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv5')(pool)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(pool)\n",
    "    dense = Dense(100, activation='relu', name='dense1')(flat)\n",
    "    drop = Dropout(rate=0.2)(dense)\n",
    "    dense = Dense(40, activation='relu', name='dense2')(drop)\n",
    "    drop = Dropout(rate=0.2)(dense)\n",
    "    \n",
    "    output = Dense(MOVES, activation='linear', name='output')(drop)\n",
    "    \n",
    "    model = Model(inputs=screen_input, outputs=output)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainModelOffline(states, actions, labels, nextStates, \n",
    "                      epochs, \n",
    "                      batchSize=32, \n",
    "                      file='data/models/model.h5', \n",
    "                      load=False,\n",
    "                      status=True\n",
    "                     ):\n",
    "    '''Train a model offline. \n",
    "    Can load or generate a new model. Saves the model after each epoch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    states: the list of batches of images representing the current states\n",
    "    actions: the list of actions taken\n",
    "    labels: the list of rewards obtained\n",
    "    nextStates: the list of batches of images representing the next states\n",
    "    epochs: the number of training epochs\n",
    "    batchSize: the training batch size\n",
    "    file: the model file, used for saving and loading\n",
    "    load: if true, the model is loaded from the file, otherwise a new model is generated\n",
    "    status: if true, print the status of the training\n",
    "    '''\n",
    "    \n",
    "    if load:\n",
    "        model = load_model(file)  \n",
    "        print('Model loaded.')\n",
    "    else:\n",
    "        model = nn_model_actionoutput()\n",
    "\n",
    "    dataSize = len(states)\n",
    "    \n",
    "    # For each epoch\n",
    "    for i in range(epochs):\n",
    "        print('Epoch', i+1)\n",
    "    \n",
    "        batchStart = 0\n",
    "        batchEnd = min(batchSize, dataSize)\n",
    "    \n",
    "        # For each batch\n",
    "        while batchStart < batchEnd:\n",
    "\n",
    "            targets = []\n",
    "            \n",
    "            b = batchStart\n",
    "            # For each experience of the batch, recalculate the targets according to the Q algorithm\n",
    "            while b < dataSize and b < batchEnd:\n",
    "                # Get the features of the experience\n",
    "                s = states[b : b+1]\n",
    "                a = actions[b]\n",
    "                l = labels[b]\n",
    "                n = nextStates[b: b+1]\n",
    "                \n",
    "                target = l\n",
    "                if l != DEAD_REWARD:\n",
    "                    target = l + GAMMA * np.amax(model.predict(n))\n",
    "                \n",
    "                fullTarget = model.predict(s)\n",
    "                fullTarget[0][a] = target\n",
    "                \n",
    "                targets.append(fullTarget[0])\n",
    "                \n",
    "                b += 1\n",
    "            \n",
    "            print(batchStart, '/', dataSize, end='\\r')\n",
    "                \n",
    "            # Fit the model with the batch\n",
    "            targets = np.asarray(targets)\n",
    "            model.fit(states[batchStart:batchEnd], targets, epochs=1, verbose=0)\n",
    "\n",
    "            batchStart = batchEnd\n",
    "            batchEnd = min(batchEnd + batchSize, dataSize)\n",
    "            \n",
    "        print(dataSize, '/', dataSize)\n",
    "        print('MSE =', evaluateLabels(model, states, actions, labels, sample=50))\n",
    "        model.save(file)\n",
    "        \n",
    "        \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "913 / 913\n",
      "MSE = 0.45664884802438066\n",
      "Epoch 2\n",
      "913 / 913\n",
      "MSE = 0.25891703720917203\n",
      "Epoch 3\n",
      "913 / 913\n",
      "MSE = 0.3413278045064537\n",
      "Epoch 4\n",
      "913 / 913\n",
      "MSE = 0.18662625015892254\n",
      "Epoch 5\n",
      "913 / 913\n",
      "MSE = 0.1818491968931874\n",
      "Epoch 6\n",
      "913 / 913\n",
      "MSE = 0.18560868383718201\n",
      "Epoch 7\n",
      "913 / 913\n",
      "MSE = 0.25092413612235276\n",
      "Epoch 8\n",
      "913 / 913\n",
      "MSE = 0.14643886749753737\n",
      "Epoch 9\n",
      "913 / 913\n",
      "MSE = 0.3542502762726323\n",
      "Epoch 10\n",
      "160 / 913\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3543e5e0accd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(states.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainModelOffline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnextStates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-7189ca6a7042>\u001b[0m in \u001b[0;36mtrainModelOffline\u001b[1;34m(states, actions, labels, nextStates, epochs, batchSize, file, load, status)\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mfullTarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                 \u001b[0mfullTarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# states, actions, labels, nextStates = readBatchSamplesMove(sampleData(1000, 5, 10, 1), READ_BATCH)\n",
    "# s2, a2, l2, n2 = readBatchSamplesMove(sampleData(50, 5, 5, 1), READ_BATCH)\n",
    "# print(states.shape)\n",
    "\n",
    "model = trainModelOffline(states, actions, labels, nextStates, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLabels(model, states, actions, labels, sample=0):\n",
    "    \n",
    "    if sample > 0:\n",
    "        sample = min(sample, len(states))\n",
    "        indexes = random.sample(range(len(states)), sample)\n",
    "        states = states[indexes]\n",
    "        actions = actions[indexes]\n",
    "        labels = labels[indexes]\n",
    "        \n",
    "    res = model.predict(states)   \n",
    "    \n",
    "    sqErr = [(res[i][actions[i]] - labels[i])**2 for i, out in enumerate(res)]\n",
    "    meanSqErr = np.mean(sqErr)\n",
    "    \n",
    "    return meanSqErr\n",
    "\n",
    "\n",
    "# def evaluateMemory(model, memory, sample=0):\n",
    "    \n",
    "#     if sample > 0:\n",
    "#         sample = min(sample, len(memory))\n",
    "#         indexes = random.sample(range(len(memory)), sample)\n",
    "#         states = states[indexes]\n",
    "#         actions = actions[indexes]\n",
    "#         labels = labels[indexes]\n",
    "        \n",
    "#     res = model.predict(states)   \n",
    "    \n",
    "#     sqErr = [(res[i][actions[i]] - labels[i])**2 for i, out in enumerate(res)]\n",
    "#     meanSqErr = np.mean(sqErr)\n",
    "    \n",
    "#     return meanSqErr\n",
    "    \n",
    "    \n",
    "def evaluateTargets(model, states, actions, labels):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23553280485184794"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate(data[30:50], labels[30:50])\n",
    "evalStates = states\n",
    "evalActions = actions\n",
    "evalLabels = labels\n",
    "\n",
    "# print(model.predict(evalStates))\n",
    "# print(evalLabels)\n",
    "\n",
    "evaluateLabels(model, evalStates, evalActions, evalLabels, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 2, 137, 180)\n",
      "(193, 1)\n",
      "(193, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 193]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-c6b1f0fce75e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0msKFold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results: %.5f (%.5f)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 193]"
     ]
    }
   ],
   "source": [
    "# Build pipeline\n",
    "\n",
    "layers = []\n",
    "layers.append(('nn', KerasClassifier(build_fn=nn_model_actionlast,\n",
    "                                   epochs=5,\n",
    "                                   batch_size=10,\n",
    "                                   verbose=1)))\n",
    "estimator = Pipeline(layers)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "data, actions, labels = readBatchSamplesMove(sampleData(200, 10, 0.5, 0.5), 2)\n",
    "\n",
    "# print(labels)\n",
    "# labels = np.asarray(labels).reshape(-1, 1)\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(labels)\n",
    "# labels = scaler.transform(labels)\n",
    "# print(labels.reshape(labels.size))\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "labels = labels.reshape((labels.size, 1))\n",
    "actions = actions.reshape((actions.size, 1))\n",
    "print(data.shape)\n",
    "print(actions.shape)\n",
    "print(labels.shape)\n",
    "     \n",
    "sKFold = StratifiedKFold(n_splits=2)\n",
    "results = cross_val_score(estimator, [data, actions], labels, cv=sKFold, verbose=1, scoring='accuracy')\n",
    "\n",
    "print(\"Results: %.5f (%.5f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play game with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "url = 'https://playsnake.org/'\n",
    "\n",
    "browser = webdriver.Chrome(executable_path='D:/Libraries/Drivers/chromedriver_win32/chromedriver.exe')\n",
    "# browser = webdriver.Chrome(executable_path='C:/Personal/Proiecte/Cod/_libs/Python/selenium_chromedriver73_win32/chromedriver.exe')\n",
    "browser.get(url) \n",
    "\n",
    "maxGames = 1\n",
    "\n",
    "curModel = load_model('data/models/model_s1000_e9.h5')\n",
    "\n",
    "for g in range(maxGames):\n",
    "    \n",
    "    # Select the level\n",
    "    selectLevel(1)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    clickBoard()\n",
    "    prevScreen = getScreen()\n",
    "    \n",
    "    while getState() == 'playing' or getState() == 'paused':\n",
    "        curScreen = getScreen()\n",
    "        screens = [prevScreen, curScreen]\n",
    "        \n",
    "        m = getModelMoveOutput(curModel, screens)\n",
    "        print(m)\n",
    "        \n",
    "        clickBoard()\n",
    "        makeMove(m)\n",
    "        clickBoard()\n",
    "        \n",
    "        prevScreen = curScreen\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train game online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Sampled data.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-ea0aa969cb9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# Retrain the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainModelOnline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-113-0a3181b2535d>\u001b[0m in \u001b[0;36mtrainModelOnline\u001b[1;34m(memory, batchSize, file, load, status)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MSE ='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluateLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'actions' is not defined"
     ]
    }
   ],
   "source": [
    "url = 'https://playsnake.org/'\n",
    "\n",
    "browser = webdriver.Chrome(executable_path='D:/Libraries/Drivers/chromedriver_win32/chromedriver.exe')\n",
    "# browser = webdriver.Chrome(executable_path='C:/Personal/Proiecte/Cod/_libs/Python/selenium_chromedriver73_win32/chromedriver.exe')\n",
    "browser.get(url) \n",
    "\n",
    "maxGames = 1\n",
    "\n",
    "curModel = load_model('data/models/model_s1000_e9.h5')\n",
    "\n",
    "memory = []\n",
    "\n",
    "for g in range(maxGames):\n",
    "    \n",
    "    # Select the level\n",
    "    selectLevel(1)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    clickBoard()\n",
    "    prevScreen = getScreen()\n",
    "    \n",
    "    state = []\n",
    "    episode = []\n",
    "    score = 0\n",
    "    \n",
    "    while getState() == 'playing' or getState() == 'paused':\n",
    "        curScreen = getScreen()\n",
    "        \n",
    "        # Add the new experience to the episode\n",
    "        nextState = [prevScreen, curScreen]\n",
    "        if state and nextState:\n",
    "            exp = Experience(state, m, r, nextState)\n",
    "            episode.append(exp)\n",
    "        state = nextState\n",
    "        \n",
    "        # Make the move\n",
    "        m = getModelMoveOutput(curModel, state)\n",
    "        print('Move:', m, end='\\r')\n",
    "        \n",
    "        clickBoard()\n",
    "        makeMove(m)\n",
    "        clickBoard()\n",
    "        \n",
    "        # Calculate the reward\n",
    "        r = max(STILL_ALIVE_REWARD, getScore() - score) \n",
    "        \n",
    "        prevScreen = curScreen\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Add the episode to the memory\n",
    "    rememberExp(memory, episode)\n",
    "    \n",
    "    # Retrain the model\n",
    "    model = trainModelOnline(memory)\n",
    "    \n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = 500\n",
    "\n",
    "class Experience:\n",
    "    '''Class for an experience.'''\n",
    "    def __init__(self, state, action, label, nextState):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.label = label\n",
    "        self.nextState = nextState\n",
    "                        \n",
    "            \n",
    "def rememberExp(memory, exps):\n",
    "    '''Add new experiences to the memory.'''\n",
    "    for e in exps:\n",
    "        if len(memory) == MAX_MEMORY:\n",
    "            memory.pop(0)\n",
    "        memory.append(e)\n",
    "\n",
    "\n",
    "def sampleMemory(memory, nSamples, propD, propR, propA):\n",
    "    '''Sample experiences from the memroy according to some proportions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    memory: the remembered experiences\n",
    "    nSamples: total number of samples\n",
    "    propD: proportion of samples which represent a death\n",
    "    propR: proportion of samples which represent a reward\n",
    "    propA: proportion of rest of samples\n",
    "    '''\n",
    "    \n",
    "    nSamples = min(len(memory), nSamples)\n",
    "        \n",
    "    perc = []\n",
    "    nd, na, nr = (0, 0, 0)\n",
    "    for exp in memory:\n",
    "        r = exp.label\n",
    "        if r == DEAD_REWARD:\n",
    "            perc.append('d')\n",
    "            nd += 1\n",
    "        elif r == STILL_ALIVE_REWARD:\n",
    "            perc.append('a')\n",
    "            na += 1\n",
    "        else:\n",
    "            perc.append('r')\n",
    "            nr += 1\n",
    "        \n",
    "    n = propD * nd + propA * na + propR * nr\n",
    "    pd = propD / n\n",
    "    pa = propA / n\n",
    "    pr = propR / n\n",
    "    for i in range(len(perc)):\n",
    "        if perc[i] == 'd':\n",
    "            perc[i] = pd\n",
    "        elif perc[i] == 'a':\n",
    "            perc[i] = pa\n",
    "        else:\n",
    "            perc[i] = pr\n",
    "        \n",
    "    samples = np.random.choice(memory, size=nSamples, replace=False, p=perc)\n",
    "    print('Sampled data.')\n",
    "    return samples\n",
    "\n",
    "\n",
    "def trainModelOnline(memory, \n",
    "                      batchSize=32, \n",
    "                      file='data/models/model.h5', \n",
    "                      load=True,\n",
    "                      status=True\n",
    "                     ):\n",
    "    '''Train a model online, from the experience memory. \n",
    "    Can load or generate a new model. Saves the model at the end.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    memory: the experience memory\n",
    "    batchSize: the training batch size\n",
    "    file: the model file, used for saving and loading\n",
    "    load: if true, the model is loaded from the file, otherwise a new model is generated\n",
    "    status: if true, print the status of the training\n",
    "    '''\n",
    "    \n",
    "    if load:\n",
    "        model = load_model(file)  \n",
    "        print('Model loaded.')\n",
    "    else:\n",
    "        model = nn_model_actionoutput()\n",
    "        \n",
    "    # Sample experiences from the memory\n",
    "    batch = sampleMemory(memory, batchSize, 5, 10, 1)\n",
    "    batchSize = len(batch)\n",
    "\n",
    "    states = []\n",
    "    targets = []\n",
    "    # For each experience\n",
    "    for e in batch:        \n",
    "        target = e.label\n",
    "        if e.label != DEAD_REWARD:\n",
    "            target = e.label + GAMMA * np.amax(model.predict(np.asarray([e.nextState])))\n",
    "        \n",
    "        fullTarget = model.predict(np.asarray([e.state]))\n",
    "        fullTarget[0][e.action] = target\n",
    "        \n",
    "        targets.append(fullTarget[0])\n",
    "        states.append(e.state)\n",
    "               \n",
    "    # Fit the model with the batch\n",
    "    targets = np.asarray(targets)\n",
    "    model.fit(np.asarray(states), targets, epochs=1, verbose=0)\n",
    "        \n",
    "#     print('MSE =', evaluateLabels(model, states, actions, labels, sample=50))\n",
    "    model.save(file)\n",
    "                \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0 ...   0   0   0]\n",
      "  [  0 255 255 ... 255 255   0]\n",
      "  [  0 255 255 ... 255 255   0]\n",
      "  ...\n",
      "  [  0 255 255 ... 255 255   0]\n",
      "  [  0 255 255 ... 255 255   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0 255 255 ... 255 255   0]\n",
      "  [  0 255 255 ... 255 255   0]\n",
      "  ...\n",
      "  [  0 255 255 ... 255 255   0]\n",
      "  [  0 255 255 ... 255 255   0]\n",
      "  [  0   0   0 ...   0   0   0]]]\n",
      "[[1, 2]]\n"
     ]
    }
   ],
   "source": [
    "# exps = [3, 1]\n",
    "# rememberExp(memory, exps)\n",
    "# print(memory)\n",
    "\n",
    "# # sampleMemory(memory, 5, 5, 10, 1)\n",
    "\n",
    "# print(memory[0].state)\n",
    "print(np.asarray(memory[0].nextState))\n",
    "l = [1, 2]\n",
    "print([l])\n",
    "\n",
    "\n",
    "# Retrain the model\n",
    "# model = trainModelOnline(memory)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
