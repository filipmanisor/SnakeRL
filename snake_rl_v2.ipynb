{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idei:\n",
    "* x Overfitting: schimbat dropout\n",
    "* x Mai multe batch-uri pentru training online\n",
    "* x Verificat ca ia corect screenshots pentru state si next state\n",
    "* x Scoate actiunea \"0\"\n",
    "* x 'board' din functia makeMove e acum var globala, nu il mai cauta de fiecare data, dar sarpele tot mai sare pozitii uneori. Pot face schimbarea asta si la 'state' si 'score'\n",
    "* x Verificat daca fullTarget updateaza cum trebuie doar actiunea potrivita - Pare ok\n",
    "* x Verificat daca e un offset la stari atunci cand faci mutari conform modelului - Da, e offset\n",
    "* x Puncte constante pentru reward (100p)\n",
    "* x MakeMove doar din 2 in 2\n",
    "* x Downsampling\n",
    "* x De verificat in continuare daca se updateaza cum trebuie weights - Pare ca da, am verificat cu 3 epochs x 300 exp. Weights se schimba, dar doar putin si doar unele din centru\n",
    "* x Verificat de ce modelul pare a avea cam aceleasi rezultate in orice pozitie - Clar o problema majora era ca simplificasem prea mult modelul (nu e ok sa fie MSE f mic din prima); O alta problema majora a fost Learning Rate prea mare (l-am scazut la 0.0001)\n",
    "* x Adaugat strides la conv2d, cu stride = kernel / 2\n",
    "* x Renunta la pooling layers (?)\n",
    "* x Cea mai mare problema nu e ca tot incearca aceeasi actiune, ci ca nu invata sa evite peretele la ultima actiune - De verificat, dar posibil problema era ca nu punea la Experience -1000 la ultima cum trebuie\n",
    "* x Input cu diferenta dintre doua screenshots pentru directie, in loc de ambele screenshots - Nu merge pentru Snake, pentru ca cercurile recompena raman pe loc si ar disparea la diferenta. Merge doar pentru jocuri unde tot ce conteaza se misca.\n",
    "* x Fixed Q target pentru offline training\n",
    "\n",
    "\n",
    "* Fixed Q target pentru online training\n",
    "* Double DNN\n",
    "* Gamma mai mare\n",
    "\n",
    "\n",
    "* Considerat invatare online doar pe ultimele exemple (max memory = 32)\n",
    "\n",
    "#### Dezvoltare:\n",
    "* PrevAction ca input pentru DNN \n",
    "    - Queues: 4 screens, 3 moves, 2 rewards (if moves > 1) \n",
    "    - La fiecare adaugare de un nou reward se poate memora un nou Experience\n",
    "    - Imaginile salvate la final din Episode\n",
    "    - saveImg trebuie sa contina si prevAction\n",
    "    - pentru joc efectiv ai nevoie doar de primele 2 screens din queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "from PIL import Image, ImageOps\n",
    "from keras.models import Sequential, Model\n",
    "import keras.layers\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "import keras.losses as losses\n",
    "from keras.models import load_model\n",
    "from keras.backend import set_image_data_format\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import glob\n",
    "from collections import deque\n",
    "\n",
    "set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "STILL_ALIVE_REWARD = 0\n",
    "DEAD_REWARD = -1\n",
    "SCORE_REWARD = 1\n",
    "\n",
    "CROP_SHAPE = (750, 539, 1)\n",
    "RESIZE_WIDTH = 100\n",
    "RESIZE_HEIGHT = 71\n",
    "READ_BATCH = 2\n",
    "\n",
    "MOVES = 4\n",
    "RIGHT = 0\n",
    "DOWN = 1\n",
    "LEFT = 2\n",
    "UP = 3\n",
    "\n",
    "SHOTS_FOLDER = 'data/shots/'\n",
    "EXP_FOLDER = 'data/experience/'\n",
    "\n",
    "SAMPLE_ALIVE = 1\n",
    "SAMPLE_DEAD = 5\n",
    "SAMPLE_REWARD = 20\n",
    "\n",
    "MAX_MEMORY = 500\n",
    "\n",
    "GAMMA = 0.9\n",
    "LEARNING_RATE = 0.001\n",
    "EPS_INIT = 1.0\n",
    "EPS_MIN = 0.05\n",
    "EPS_DECAY = 0.998\n",
    "CLONE_STEPS = 6500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectLevel(l):\n",
    "    xpath = '/html/body/section/div[2]/nav/p[' + str(l+1) + ']'\n",
    "    \n",
    "    level = browser.find_element_by_xpath(xpath)\n",
    "    level.click()\n",
    "    \n",
    "    \n",
    "def clickBoard(board):        \n",
    "    try:\n",
    "        board.click()\n",
    "    except WebDriverException:\n",
    "        print('Exception')\n",
    "        return\n",
    "    \n",
    "    \n",
    "def saveScreen(fileName):    \n",
    "    state = getState()\n",
    "#     if state == 'playing' or state == 'paused':    \n",
    "    ss = browser.get_screenshot_as_file(SHOTS_FOLDER + fileName)\n",
    "    \n",
    "    \n",
    "def getScreen():\n",
    "    ss = browser.get_screenshot_as_png()\n",
    "    im = Image.open(io.BytesIO(ss))\n",
    "    \n",
    "    im = preprocImg(im)\n",
    "    return np.asarray(im.convert(\"L\"))\n",
    "    \n",
    "    \n",
    "def getState():\n",
    "    xpath = '/html/body/section/div[2]'\n",
    "    state = browser.find_element_by_xpath(xpath)\n",
    "    c = state.get_attribute('class')\n",
    "    \n",
    "    return c.split(' ')[-1]\n",
    "\n",
    "\n",
    "def getScore():\n",
    "    state = getState()\n",
    "    \n",
    "    if state == 'playing' or state == 'paused':\n",
    "        \n",
    "        xpath = '/html/body/section/div[2]/p[1]/span'\n",
    "        score = browser.find_element_by_xpath(xpath)\n",
    "\n",
    "        if not score.text.isnumeric():\n",
    "            return 0\n",
    "        return int(score.text)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def getBoard():\n",
    "    xpath = '/html/body/section/div[2]/div'\n",
    "    board = browser.find_element_by_xpath(xpath)\n",
    "    \n",
    "    return board\n",
    "\n",
    "\n",
    "def makeMove(board, m):    \n",
    "    \n",
    "    if m == RIGHT:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_RIGHT)\n",
    "    elif m == DOWN:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_DOWN)\n",
    "    elif m == LEFT:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_LEFT)\n",
    "    elif m == UP:\n",
    "        browser.find_element_by_tag_name('body').send_keys(Keys.ARROW_UP)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cropImgOld(fileName):\n",
    "    ss = plt.imread(fileName)\n",
    "\n",
    "    ss = ss[120:659, 273:1023, :]\n",
    "    \n",
    "    plt.imsave(fileName, ss)\n",
    "\n",
    "\n",
    "def saveImage(arr, file):\n",
    "    '''Save an image array to a file'''\n",
    "    img = Image.fromarray(arr.astype(np.uint8))\n",
    "    img.save(file)\n",
    "        \n",
    "\n",
    "def preprocImg(im):\n",
    "    '''Preprocess a screenshot.'''     \n",
    "    # Crop board\n",
    "    im = im.crop((273, 120, 1023, 659))\n",
    "    \n",
    "    # Grayscale\n",
    "    im = ImageOps.grayscale(im)\n",
    "    \n",
    "    # Binarization\n",
    "    t = 127\n",
    "    im = im.point(lambda x: 255 if x > t else 0)\n",
    "    \n",
    "    # Resize\n",
    "    im = im.resize((RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "    \n",
    "    return im\n",
    "    \n",
    "    \n",
    "def preprocAll(gameIndex):\n",
    "    '''Preprocess all screenshots in the data folder.'''\n",
    "    files = os.listdir(SHOTS_FOLDER)\n",
    "    for f in files:\n",
    "        g = parseName(f)[0]\n",
    "        \n",
    "        if g >= gameIndex:        \n",
    "            fileName =  SHOTS_FOLDER + f\n",
    "            im = Image.open(fileName)   \n",
    "            im = preprocImg(im)\n",
    "            im.save(fileName)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN action output\n",
    "\n",
    "Functional API, citeste batch-uri de imagini, considera actiunea ca output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nn_model_actionoutput():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Action as output, final layer has as many neurons as possible actions.'''\n",
    "    \n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv1')(screen_input)\n",
    "#     conv = Conv2D(16, (4, 4), activation='relu', name='conv2')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool1')(conv)\n",
    "    \n",
    "    conv = Conv2D(32, (4, 4), activation='relu', name='conv3')(pool)\n",
    "#     conv = Conv2D(8, (4, 4), activation='relu', name='conv4')(conv)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool2')(conv)\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), activation='relu', name='conv5')(pool)\n",
    "    pool = MaxPool2D(pool_size=(2,2), name='pool3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(pool)\n",
    "    dense = Dense(100, activation='relu', name='dense1')(flat)\n",
    "    drop = Dropout(rate=0.0, name='dropout1')(dense)\n",
    "    dense = Dense(40, activation='relu', name='dense2')(drop)\n",
    "    drop = Dropout(rate=0.0, name='dropout2')(dense)\n",
    "    \n",
    "    output = Dense(MOVES, activation='linear', name='output')(drop)\n",
    "    \n",
    "    model = Model(inputs=screen_input, outputs=output)\n",
    "    \n",
    "    optimizer = Adam(lr=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def nn_model_nopool():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Action as output, final layer has as many neurons as possible actions.\n",
    "    Does not use pooling layers, only strides.'''\n",
    "    \n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(16, (4, 4), strides=(2, 2), activation='relu', name='conv1')(screen_input)    \n",
    "    conv = Conv2D(32, (4, 4), strides=(2, 2), activation='relu', name='conv2')(conv)    \n",
    "    conv = Conv2D(16, (4, 4), strides=(2, 2), activation='relu', name='conv3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(conv)\n",
    "    dense = Dense(100, activation='relu', name='dense1')(flat)\n",
    "    drop = Dropout(rate=0.0, name='dropout1')(dense)\n",
    "    dense = Dense(40, activation='relu', name='dense2')(drop)\n",
    "    drop = Dropout(rate=0.0, name='dropout2')(dense)\n",
    "    \n",
    "    output = Dense(MOVES, activation='linear', name='output')(drop)\n",
    "    \n",
    "    model = Model(inputs=screen_input, outputs=output)\n",
    "    \n",
    "    optimizer = Adam(lr=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def nn_model_deepmind():\n",
    "    '''Full NN model, using the Keras Functional API.\n",
    "    Action as output, final layer has as many neurons as possible actions.\n",
    "    The structure of the NN is the same as the initial one used by DeepMind.'''\n",
    "    \n",
    "    screen_input = Input(shape=(READ_BATCH, RESIZE_HEIGHT, RESIZE_WIDTH), name='screen_input')\n",
    "    \n",
    "    conv = Conv2D(32, (8, 8), strides=(4, 4), activation='relu', name='conv1')(screen_input)\n",
    "    conv = Conv2D(64, (4, 4), strides=(2, 2), activation='relu', name='conv2')(conv)\n",
    "    conv = Conv2D(64, (3, 3), activation='relu', name='conv3')(conv)\n",
    "    \n",
    "    flat = Flatten(name='flat')(conv)\n",
    "    dense = Dense(512, activation='relu', name='dense')(flat)    \n",
    "    output = Dense(MOVES, activation='linear', name='output')(dense)\n",
    "    \n",
    "    model = Model(inputs=screen_input, outputs=output)\n",
    "    \n",
    "    optimizer = RMSprop(lr=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer = optimizer)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experience class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Experience:\n",
    "    '''Class for an experience.'''    \n",
    "    \n",
    "    def __init__(self, state=[], action=0, label=0, nextState=[]):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.label = label\n",
    "        self.nextState = nextState\n",
    "        \n",
    "        \n",
    "    def save(self, folder, index):\n",
    "        '''Save experience to a file.'''\n",
    "\n",
    "        file = folder + str(index).zfill(4) + '_' + str(self.action) + '_' + str(self.label) + '.xp'\n",
    "        f = open(file, 'w')\n",
    "\n",
    "        for s in self.state:\n",
    "            list = s.flatten()\n",
    "            for l in list:\n",
    "                f.write(str(l) + ' ')\n",
    "            f.write('\\n')\n",
    "\n",
    "        for s in self.nextState:\n",
    "            list = s.flatten()\n",
    "            for l in list:\n",
    "                f.write(str(l) + ' ')\n",
    "            f.write('\\n')\n",
    "\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    def readArray(self, line):\n",
    "        '''Read an array representing an screenshot from a file.'''\n",
    "        elems = line.split(' ')[:-1]\n",
    "\n",
    "        a = []\n",
    "        for e in elems:\n",
    "            a.append(int(e))\n",
    "\n",
    "        a = np.asarray(a)\n",
    "        a = a.reshape(RESIZE_HEIGHT, RESIZE_WIDTH)\n",
    "\n",
    "        return a\n",
    "\n",
    "    \n",
    "    def read(self, folder, file):\n",
    "        '''Read an experience from a file.'''\n",
    "        f = open(folder + file, 'r')\n",
    "\n",
    "        elems = parseExpName(file)\n",
    "        self.action = int(elems[1])\n",
    "        self.label = int(elems[2])\n",
    "\n",
    "        s1 = self.readArray(f.readline())\n",
    "        s2 = self.readArray(f.readline())\n",
    "        self.state = [s1, s2]\n",
    "\n",
    "        ns1 = self.readArray(f.readline())\n",
    "        ns2 = self.readArray(f.readline())\n",
    "        self.nextState = [ns1, ns2]\n",
    "\n",
    "        f.close()\n",
    "                        \n",
    "            \n",
    "def rememberExp(memory, exps):\n",
    "    '''Add new experiences to the memory.'''\n",
    "    for e in exps:\n",
    "        if len(memory) == MAX_MEMORY:\n",
    "            memory.pop(0)\n",
    "        memory.append(e)\n",
    "\n",
    "\n",
    "def sampleMemory(memory, nSamples, propD, propR, propA):\n",
    "    '''Sample experiences from the memroy according to some proportions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    memory: the remembered experiences\n",
    "    nSamples: total number of samples\n",
    "    propD: proportion of samples which represent a death\n",
    "    propR: proportion of samples which represent a reward\n",
    "    propA: proportion of rest of samples\n",
    "    '''\n",
    "    \n",
    "    nSamples = min(len(memory), nSamples)\n",
    "        \n",
    "    perc = []\n",
    "    nd, na, nr = (0, 0, 0)\n",
    "    for exp in memory:\n",
    "        r = exp.label\n",
    "        if r == DEAD_REWARD:\n",
    "            perc.append('d')\n",
    "            nd += 1\n",
    "        elif r == STILL_ALIVE_REWARD:\n",
    "            perc.append('a')\n",
    "            na += 1\n",
    "        else:\n",
    "            perc.append('r')\n",
    "            nr += 1\n",
    "        \n",
    "    n = propD * nd + propA * na + propR * nr\n",
    "    pd = propD / n\n",
    "    pa = propA / n\n",
    "    pr = propR / n\n",
    "    for i in range(len(perc)):\n",
    "        if perc[i] == 'd':\n",
    "            perc[i] = pd\n",
    "        elif perc[i] == 'a':\n",
    "            perc[i] = pa\n",
    "        else:\n",
    "            perc[i] = pr\n",
    "        \n",
    "    samples = np.random.choice(memory, size=nSamples, replace=False, p=perc)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def parseExpName(file):\n",
    "    return file[:-3].split('_')\n",
    "\n",
    "\n",
    "def sampleFiles(nSamples,\n",
    "                folder=EXP_FOLDER,\n",
    "                propD=SAMPLE_DEAD, \n",
    "                propR=SAMPLE_REWARD,\n",
    "                propA=SAMPLE_ALIVE):\n",
    "    '''Sample the experience files according to some proportions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nSamples: total number of samples\n",
    "    folder: the experience folder\n",
    "    propD: proportion of samples which represent a death\n",
    "    propR: proportion of samples which represent a reward\n",
    "    propA: proportion of rest of samples\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(folder)\n",
    "    nSamples = min(nSamples, len(files))\n",
    "    \n",
    "    perc = []\n",
    "    nd, na, nr = (0, 0, 0)\n",
    "    for f in files:\n",
    "        r = parseExpName(f)[2]\n",
    "        if r == DEAD_REWARD:\n",
    "            perc.append('d')\n",
    "            nd += 1\n",
    "        elif r == STILL_ALIVE_REWARD:\n",
    "            perc.append('a')\n",
    "            na += 1\n",
    "        else:\n",
    "            perc.append('r')\n",
    "            nr += 1\n",
    "        \n",
    "    n = propD * nd + propA * na + propR * nr\n",
    "    pd = propD / n\n",
    "    pa = propA / n\n",
    "    pr = propR / n\n",
    "    for i in range(len(perc)):\n",
    "        if perc[i] == 'd':\n",
    "            perc[i] = pd\n",
    "        elif perc[i] == 'a':\n",
    "            perc[i] = pa\n",
    "        else:\n",
    "            perc[i] = pr\n",
    "        \n",
    "    samples = np.random.choice(files, size=nSamples, replace=False, p=perc)\n",
    "    print('Sampled data.')\n",
    "    return samples\n",
    "\n",
    "\n",
    "def readSamples(samples):\n",
    "    '''Read samples from experience files.'''\n",
    "    states = []\n",
    "    actions = []\n",
    "    labels = []\n",
    "    nextStates = []\n",
    "    \n",
    "    for i, file in enumerate(samples):    \n",
    "        exp = Experience()\n",
    "        exp.read(EXP_FOLDER, file)\n",
    "            \n",
    "        states.append(exp.state)\n",
    "        actions.append(exp.action)\n",
    "        labels.append(exp.label)\n",
    "        nextStates.append(exp.nextState)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "    states = np.asarray(states)\n",
    "    actions = np.asarray(actions)\n",
    "    nextStates = np.asarray(nextStates)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    return states, actions, labels, nextStates\n",
    "\n",
    "\n",
    "def getLastExpIndex(folder):\n",
    "    '''Get the index of the last experience.'''\n",
    "    files = os.listdir(folder)\n",
    "    if len(files) == 0:\n",
    "        return 0\n",
    "\n",
    "    last = files[-1]\n",
    "    index = parseExpName(last)[0]\n",
    "    \n",
    "    return int(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluateLabels(model, states, actions, labels, sample=0):\n",
    "    \n",
    "    if sample > 0:\n",
    "        sample = min(sample, len(states))\n",
    "        indexes = random.sample(range(len(states)), sample)\n",
    "        states = states[indexes]\n",
    "        actions = actions[indexes]\n",
    "        labels = labels[indexes]\n",
    "        \n",
    "    res = model.predict(states)   \n",
    "    \n",
    "    sqErr = [(res[i][actions[i]] - labels[i])**2 for i, out in enumerate(res)]\n",
    "    meanSqErr = np.mean(sqErr)\n",
    "    \n",
    "    return meanSqErr\n",
    "\n",
    "    \n",
    "def moveString(m):\n",
    "    if m == RIGHT:\n",
    "        return 'right'\n",
    "    elif m == DOWN:\n",
    "        return 'down '\n",
    "    elif m == LEFT:\n",
    "        return 'left '\n",
    "    elif m == UP:\n",
    "        return 'up   '\n",
    "    else:\n",
    "        return 'none '\n",
    "    \n",
    "    \n",
    "def getMoveOutputEps(model, screens, eps):\n",
    "    '''Get the move from the model which produces move scores as outputs, with an epsilon probability for exploration.'''\n",
    "    \n",
    "    # If there is a model\n",
    "    if model != False:        \n",
    "        p = random.random()\n",
    "        \n",
    "        # If exploitation was chosen\n",
    "        if p > eps:\n",
    "            res = model.predict(np.asarray([screens]))\n",
    "            m = np.argmax(res)\n",
    "            print('Model:', moveString(m), end='\\r')\n",
    "\n",
    "            return m\n",
    "   \n",
    "    # If there is no model or exploration was chosen\n",
    "    m = int(MOVES * random.random())\n",
    "    print('Rando:', moveString(m), end='\\r')\n",
    "    \n",
    "    return m \n",
    "\n",
    "\n",
    "def copyModel(model, func):\n",
    "    '''Copy a model and its weights.'''\n",
    "    newModel = func()\n",
    "    newModel.set_weights(model.get_weights())\n",
    "    \n",
    "    return newModel\n",
    "    \n",
    "\n",
    "def trainModelOnline(memory, \n",
    "                     model,\n",
    "                     batchSize=32, \n",
    "                     batches=1,\n",
    "                     file='data/models/model.h5',\n",
    "                     status=True\n",
    "                     ):\n",
    "    '''Train a model online, from the experience memory. \n",
    "    Saves the model at the end.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    memory: the experience memory\n",
    "    model: the model to be trained\n",
    "    batchSize: the training batch size\n",
    "    batches: number of batches to train on\n",
    "    file: the model file, used for saving\n",
    "    status: if true, print the status of the training\n",
    "    '''\n",
    "        \n",
    "    # Sample experiences from the memory\n",
    "    samples = sampleMemory(memory, batches * batchSize, 5, 10, 1)\n",
    "    batchSize = min(batchSize, len(samples))\n",
    "    \n",
    "    # For each batch\n",
    "    bStart = 0\n",
    "    \n",
    "    while bStart < len(samples):\n",
    "        \n",
    "        bStop = min(bStart + batchSize, len(samples))\n",
    "    \n",
    "        states = []\n",
    "        targets = []\n",
    "        \n",
    "        # For each experience\n",
    "        while bStart < bStop: \n",
    "            e = samples[bStart]\n",
    "            target = e.label\n",
    "            \n",
    "            if target != DEAD_REWARD:\n",
    "                target = e.label + GAMMA * np.amax(model.predict(np.asarray([e.nextState])))\n",
    "\n",
    "            fullTarget = model.predict(np.asarray([e.state]))\n",
    "            fullTarget[0][e.action] = target\n",
    "\n",
    "            targets.append(fullTarget[0])\n",
    "            states.append(e.state)\n",
    "            \n",
    "            bStart += 1\n",
    "\n",
    "        # Fit the model with the batch\n",
    "        targets = np.asarray(targets)\n",
    "\n",
    "        model.train_on_batch(np.asarray(states), targets)\n",
    "        \n",
    "        bStart = bStop\n",
    "        \n",
    "    model.save(file)\n",
    "                \n",
    "    return model\n",
    "\n",
    "\n",
    "def trainModelOffline(states, actions, labels, nextStates, \n",
    "                      epochs, \n",
    "                      batchSize=32, \n",
    "                      file='data/models/model.h5', \n",
    "                      load=False,\n",
    "                      status=True,\n",
    "                      modelFunc=nn_model_actionoutput\n",
    "                     ):\n",
    "    '''Train a model offline. \n",
    "    Can load or generate a new model. Saves the model after each epoch.\n",
    "    Implements Fixed Q-target.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    states: the list of batches of images representing the current states\n",
    "    actions: the list of actions taken\n",
    "    labels: the list of rewards obtained\n",
    "    nextStates: the list of batches of images representing the next states\n",
    "    epochs: the number of training epochs\n",
    "    batchSize: the training batch size\n",
    "    file: the model file, used for saving and loading\n",
    "    load: if true, the model is loaded from the file, otherwise a new model is generated\n",
    "    status: if true, print the status of the training\n",
    "    modelFunc: the type of model to use, given by the model creation function\n",
    "    '''\n",
    "    \n",
    "    if load:\n",
    "        model = load_model(file)\n",
    "        print('Model loaded.')\n",
    "    else:\n",
    "        model = modelFunc()\n",
    "        \n",
    "    # Initialize the target model\n",
    "    targetModel = copyModel(model, modelFunc)\n",
    "\n",
    "    dataSize = len(states)\n",
    "    \n",
    "    # For each epoch\n",
    "    for i in range(epochs):\n",
    "        if status:\n",
    "            print('Epoch', i+1)\n",
    "        \n",
    "        time1 = time.time()\n",
    "    \n",
    "        batchStart = 0\n",
    "        batchEnd = min(batchSize, dataSize)\n",
    "    \n",
    "        # For each batch\n",
    "        while batchStart < batchEnd:\n",
    "\n",
    "            targets = []\n",
    "            \n",
    "            b = batchStart\n",
    "            # For each experience of the batch, recalculate the targets according to the Q algorithm\n",
    "            while b < dataSize and b < batchEnd:\n",
    "                # Get the features of the experience\n",
    "                s = states[b : b+1]\n",
    "                a = actions[b]\n",
    "                l = labels[b]\n",
    "                n = nextStates[b: b+1]\n",
    "                \n",
    "                target = l\n",
    "                if l != DEAD_REWARD:\n",
    "                    target = l + GAMMA * np.amax(targetModel.predict(n))\n",
    "                \n",
    "                fullTarget = model.predict(s)\n",
    "                fullTarget[0][a] = target\n",
    "                \n",
    "                targets.append(fullTarget[0])\n",
    "                \n",
    "                # Clone target model\n",
    "                if (i * len(states) + b) % CLONE_STEPS == 0:\n",
    "                    targetModel = copyModel(model, modelFunc)\n",
    "                \n",
    "                b += 1\n",
    "            \n",
    "            if status and batchStart % (batchSize * 2) == 0:\n",
    "                print(batchStart, '/', dataSize, end='\\r')\n",
    "                \n",
    "            # Fit the model with the batch\n",
    "            targets = np.asarray(targets)\n",
    "            model.train_on_batch(states[batchStart:batchEnd], targets)\n",
    "\n",
    "            batchStart = batchEnd\n",
    "            batchEnd = min(batchEnd + batchSize, dataSize)\n",
    "          \n",
    "        if status:  \n",
    "            print(dataSize, '/', dataSize)\n",
    "            print(\"  MSE = %.2f\" % evaluateLabels(model, states, actions, labels, sample=50))\n",
    "        \n",
    "        time2 = time.time()\n",
    "        \n",
    "        if status:\n",
    "            print(\"  Duration: %.2f s\" % (time2- time1))\n",
    "            \n",
    "        # Save model every 10 epochs\n",
    "        if i % 2 == 0:\n",
    "            model.save(file)  \n",
    "      \n",
    "    model.save(file)  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(games,\n",
    "         train=False,\n",
    "         useModel=False,\n",
    "         saveExp=False,\n",
    "         modelFile='data/models/model.h5',\n",
    "         saveFolder=EXP_FOLDER,\n",
    "         modelFunc=nn_model_actionoutput):\n",
    "    \n",
    "    '''Makes a move every second tick. The previous action does not influence the current action.'''\n",
    "    \n",
    "    global browser\n",
    "    \n",
    "    e = EPS_INIT\n",
    "    \n",
    "    expIndex = getLastExpIndex(saveFolder) + 1\n",
    "    \n",
    "    url = 'https://playsnake.org/'\n",
    "#     browser = webdriver.Chrome(executable_path='D:/Libraries/Drivers/chromedriver_win32/chromedriver.exe')\n",
    "    browser = webdriver.Chrome(executable_path='C:/Personal/Proiecte/Cod/_libs/Python/selenium_chromedriver73_win32/chromedriver.exe')\n",
    "    browser.get(url) \n",
    "    memory = []\n",
    "    \n",
    "    # Load model\n",
    "    if useModel == True:\n",
    "        curModel = load_model(modelFile)\n",
    "    elif train == True:\n",
    "        curModel = modelFunc()\n",
    "    else:\n",
    "        curModel = False\n",
    "\n",
    "    for g in range(games):\n",
    "\n",
    "        score = 0\n",
    "        screenIndex = 0\n",
    "        time1 = time.time()\n",
    "    \n",
    "        episode = []        \n",
    "        finalScore = 0\n",
    "\n",
    "        # Select the level\n",
    "        selectLevel(1)        \n",
    "        while getState() == 'countdown':\n",
    "            pass  \n",
    "        board = getBoard()      \n",
    "\n",
    "        clickBoard(board)\n",
    "        screens = deque([], 4)\n",
    "        \n",
    "        index = 0\n",
    "        \n",
    "        while getState() == 'playing' or getState() == 'paused':\n",
    "                \n",
    "            # Get current screenshot\n",
    "            screens.append(getScreen())            \n",
    "\n",
    "            # Every two screens\n",
    "            if index % 2 == 1:\n",
    "\n",
    "                # Calculate the reward for the previous move\n",
    "                r = STILL_ALIVE_REWARD\n",
    "                if getScore() - score > 0:\n",
    "                    r = SCORE_REWARD \n",
    "\n",
    "                score = getScore()\n",
    "                finalScore = max(finalScore, score)  \n",
    "                      \n",
    "                # Form the current state\n",
    "                state = [screens[-2], screens[-1]]\n",
    "            \n",
    "                if index > 2:\n",
    "                    # Save experience\n",
    "                    prevState = [screens[0], screens[1]]\n",
    "                    exp = Experience(prevState, m, r, state)\n",
    "                    episode.append(exp)  \n",
    "                \n",
    "                # Get the current move\n",
    "                m = getMoveOutputEps(curModel, state, e)\n",
    "            \n",
    "                # Send the move to the board\n",
    "                clickBoard(board)\n",
    "                makeMove(board, m)\n",
    "                clickBoard(board) \n",
    "            \n",
    "            else:\n",
    "                # Move to next screenshot\n",
    "                clickBoard(board)\n",
    "                clickBoard(board) \n",
    "\n",
    "            index += 1\n",
    "        \n",
    "        # Add last experience\n",
    "        if index % 2 == 1:\n",
    "            state = [screens[3], screens[3]]\n",
    "            prevState = [screens[1], screens[2]]\n",
    "            exp = Experience(prevState, m, DEAD_REWARD, state)\n",
    "            episode.append(exp) \n",
    "            \n",
    "        # Update last experience\n",
    "        else:\n",
    "            exp = episode[-1]\n",
    "            exp.label = DEAD_REWARD\n",
    "            \n",
    "        \n",
    "        time2 = time.time()        \n",
    "        print(\"%d: %.2f s, %d points\" % (g, time2-time1, finalScore)) \n",
    "        \n",
    "        # Save experiences\n",
    "        if saveExp:\n",
    "            for exp in episode:\n",
    "                exp.save(saveFolder, expIndex)\n",
    "                expIndex += 1  \n",
    "        \n",
    "        # Only save experiences with positive rewards\n",
    "        else:\n",
    "            for exp in episode:\n",
    "                if exp.label > 0:\n",
    "                    exp.save(saveFolder, expIndex)\n",
    "                    expIndex += 1  \n",
    "            \n",
    "        if train:     \n",
    "            # Add the episode to the memory\n",
    "            rememberExp(memory, episode)\n",
    "\n",
    "            # Retrain the model            \n",
    "            curModel = trainModelOnline(memory, model=curModel, file=modelFile, batches=5)\n",
    "        else:\n",
    "            time.sleep(1)            \n",
    "            \n",
    "        if e > EPS_MIN:\n",
    "            e = e * EPS_DECAY\n",
    "\n",
    "    browser.quit()\n",
    "    \n",
    "    \n",
    "    ### DEBUGGING\n",
    "    return episode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 13.21 s, 0 points\n",
      "1: 24.60 s, 0 points\n",
      "2: 16.41 s, 0 points\n",
      "3: 16.12 s, 0 points\n",
      "4: 12.75 s, 0 points\n",
      "5: 17.03 s, 0 points\n",
      "6: 27.35 s, 0 points\n",
      "7: 33.22 s, 0 points\n",
      "8: 19.88 s, 0 points\n",
      "9: 11.09 s, 0 points\n",
      "10: 45.16 s, 0 points\n",
      "11: 39.40 s, 0 points\n",
      "12: 19.66 s, 0 points\n",
      "13: 59.45 s, 0 points\n",
      "14: 36.46 s, 0 points\n",
      "15: 113.45 s, 0 points\n",
      "16: 40.28 s, 0 points\n",
      "17: 48.86 s, 0 points\n",
      "18: 6.96 s, 0 points\n",
      "19: 38.81 s, 5 points\n",
      "20: 44.32 s, 5 points\n",
      "21: 20.62 s, 0 points\n",
      "22: 15.16 s, 0 points\n",
      "23: 13.25 s, 0 points\n",
      "24: 24.57 s, 0 points\n",
      "25: 49.24 s, 5 points\n",
      "26: 12.16 s, 0 points\n",
      "27: 14.02 s, 0 points\n",
      "28: 40.04 s, 0 points\n",
      "29: 22.71 s, 0 points\n",
      "30: 9.81 s, 0 points\n",
      "31: 11.60 s, 0 points\n",
      "32: 16.85 s, 0 points\n",
      "33: 73.19 s, 25 points\n",
      "34: 31.28 s, 0 points\n",
      "35: 38.07 s, 0 points\n",
      "36: 29.47 s, 0 points\n",
      "37: 13.44 s, 0 points\n",
      "38: 26.22 s, 0 points\n",
      "39: 24.81 s, 0 points\n",
      "40: 72.94 s, 0 points\n",
      "41: 19.79 s, 0 points\n",
      "42: 12.33 s, 0 points\n",
      "43: 15.94 s, 0 points\n",
      "44: 13.94 s, 0 points\n",
      "45: 31.48 s, 0 points\n",
      "46: 40.56 s, 0 points\n",
      "47: 28.39 s, 0 points\n",
      "48: 25.72 s, 0 points\n",
      "49: 16.48 s, 0 points\n",
      "50: 35.35 s, 0 points\n",
      "51: 26.14 s, 0 points\n",
      "52: 56.09 s, 0 points\n",
      "53: 12.15 s, 0 points\n",
      "54: 26.26 s, 0 points\n",
      "55: 9.12 s, 0 points\n",
      "56: 52.85 s, 0 points\n",
      "57: 24.15 s, 0 points\n",
      "58: 17.77 s, 0 points\n",
      "59: 16.85 s, 0 points\n",
      "60: 26.67 s, 0 points\n",
      "61: 11.55 s, 0 points\n",
      "62: 27.38 s, 0 points\n",
      "63: 14.55 s, 0 points\n",
      "64: 12.66 s, 0 points\n",
      "65: 56.49 s, 0 points\n",
      "66: 61.01 s, 0 points\n",
      "67: 15.12 s, 0 points\n",
      "68: 26.09 s, 0 points\n",
      "69: 12.77 s, 0 points\n",
      "70: 19.46 s, 0 points\n",
      "71: 26.33 s, 0 points\n",
      "72: 11.94 s, 0 points\n",
      "73: 27.08 s, 0 points\n",
      "74: 43.23 s, 0 points\n",
      "75: 67.22 s, 5 points\n",
      "76: 39.18 s, 0 points\n",
      "77: 37.43 s, 0 points\n",
      "78: 22.85 s, 0 points\n",
      "79: 19.66 s, 0 points\n",
      "80: 17.19 s, 0 points\n",
      "81: 37.96 s, 0 points\n",
      "82: 16.93 s, 70 points\n",
      "83: 12.49 s, 0 points\n",
      "84: 19.44 s, 0 points\n",
      "85: 18.50 s, 0 points\n",
      "86: 32.37 s, 0 points\n",
      "87: 18.27 s, 0 points\n",
      "88: 22.12 s, 0 points\n",
      "89: 41.56 s, 0 points\n",
      "90: 28.92 s, 0 points\n",
      "91: 12.61 s, 0 points\n",
      "92: 33.78 s, 0 points\n",
      "93: 26.53 s, 0 points\n",
      "94: 13.23 s, 0 points\n",
      "95: 16.21 s, 0 points\n",
      "96: 36.36 s, 0 points\n",
      "97: 41.18 s, 0 points\n",
      "98: 12.59 s, 0 points\n",
      "99: 73.31 s, 0 points\n",
      "100: 15.80 s, 0 points\n",
      "101: 23.45 s, 0 points\n",
      "102: 31.62 s, 0 points\n",
      "103: 37.54 s, 0 points\n",
      "104: 27.51 s, 0 points\n",
      "105: 47.12 s, 0 points\n",
      "106: 25.89 s, 0 points\n",
      "107: 29.59 s, 0 points\n",
      "108: 21.91 s, 0 points\n",
      "109: 23.44 s, 0 points\n",
      "110: 27.96 s, 0 points\n",
      "111: 38.67 s, 0 points\n",
      "112: 84.43 s, 0 points\n",
      "113: 39.07 s, 5 points\n",
      "114: 18.17 s, 0 points\n",
      "115: 65.30 s, 0 points\n",
      "116: 32.41 s, 0 points\n",
      "117: 64.04 s, 0 points\n",
      "118: 22.87 s, 0 points\n",
      "119: 36.61 s, 0 points\n",
      "120: 37.98 s, 0 points\n",
      "121: 35.02 s, 0 points\n",
      "122: 18.28 s, 0 points\n",
      "123: 17.64 s, 0 points\n",
      "124: 15.96 s, 0 points\n",
      "125: 42.92 s, 0 points\n",
      "126: 19.94 s, 0 points\n",
      "127: 33.25 s, 105 points\n",
      "128: 14.20 s, 0 points\n",
      "129: 75.08 s, 0 points\n",
      "130: 26.01 s, 0 points\n",
      "131: 24.21 s, 0 points\n",
      "132: 13.20 s, 0 points\n",
      "133: 18.69 s, 0 points\n",
      "134: 69.53 s, 0 points\n",
      "135: 10.98 s, 0 points\n",
      "136: 17.76 s, 0 points\n",
      "137: 59.60 s, 0 points\n",
      "138: 9.24 s, 0 points\n",
      "139: 18.38 s, 0 points\n",
      "140: 28.26 s, 0 points\n",
      "141: 22.55 s, 0 points\n",
      "142: 22.01 s, 0 points\n",
      "143: 23.10 s, 0 points\n",
      "144: 19.69 s, 0 points\n",
      "145: 30.76 s, 0 points\n",
      "146: 66.60 s, 0 points\n",
      "147: 35.69 s, 0 points\n",
      "148: 11.66 s, 0 points\n",
      "149: 16.13 s, 0 points\n",
      "150: 11.48 s, 0 points\n",
      "151: 28.50 s, 0 points\n",
      "152: 34.31 s, 15 points\n",
      "153: 26.78 s, 0 points\n",
      "154: 60.81 s, 0 points\n",
      "155: 90.95 s, 5 points\n",
      "156: 44.65 s, 0 points\n",
      "157: 18.13 s, 0 points\n",
      "158: 22.29 s, 0 points\n",
      "159: 16.20 s, 0 points\n",
      "160: 22.28 s, 0 points\n",
      "161: 34.84 s, 0 points\n",
      "162: 52.75 s, 0 points\n",
      "163: 91.27 s, 0 points\n",
      "164: 27.99 s, 0 points\n",
      "165: 28.31 s, 30 points\n",
      "166: 28.78 s, 0 points\n",
      "167: 12.47 s, 0 points\n",
      "168: 38.42 s, 0 points\n",
      "169: 11.30 s, 0 points\n",
      "170: 17.60 s, 0 points\n",
      "171: 63.80 s, 5 points\n",
      "172: 8.70 s, 0 points\n",
      "173: 32.51 s, 0 points\n",
      "174: 38.36 s, 0 points\n",
      "175: 35.34 s, 0 points\n",
      "176: 13.56 s, 0 points\n",
      "177: 34.88 s, 0 points\n",
      "178: 38.72 s, 0 points\n",
      "179: 28.76 s, 0 points\n",
      "180: 49.32 s, 0 points\n",
      "181: 19.16 s, 0 points\n",
      "182: 20.90 s, 5 points\n",
      "183: 14.87 s, 0 points\n",
      "184: 30.14 s, 0 points\n",
      "185: 16.07 s, 0 points\n",
      "186: 56.84 s, 0 points\n",
      "187: 13.77 s, 0 points\n",
      "188: 12.03 s, 95 points\n",
      "189: 16.37 s, 0 points\n",
      "190: 14.37 s, 0 points\n",
      "191: 41.44 s, 0 points\n",
      "192: 13.00 s, 0 points\n",
      "193: 80.03 s, 5 points\n",
      "194: 15.42 s, 0 points\n",
      "195: 28.94 s, 0 points\n",
      "196: 19.36 s, 0 points\n",
      "197: 38.61 s, 0 points\n",
      "198: 21.64 s, 0 points\n",
      "199: 44.24 s, 0 points\n",
      "200: 17.73 s, 0 points\n",
      "201: 44.25 s, 0 points\n",
      "202: 38.76 s, 0 points\n",
      "203: 41.00 s, 0 points\n",
      "204: 56.29 s, 5 points\n",
      "205: 39.15 s, 0 points\n",
      "206: 74.37 s, 0 points\n",
      "207: 35.15 s, 0 points\n",
      "208: 15.79 s, 0 points\n",
      "209: 26.39 s, 0 points\n",
      "210: 50.06 s, 0 points\n",
      "211: 21.47 s, 0 points\n",
      "212: 26.87 s, 0 points\n",
      "213: 24.18 s, 100 points\n",
      "214: 53.03 s, 0 points\n",
      "215: 13.96 s, 0 points\n",
      "216: 67.16 s, 0 points\n",
      "217: 15.80 s, 0 points\n",
      "218: 14.33 s, 0 points\n",
      "219: 59.51 s, 0 points\n",
      "220: 11.61 s, 0 points\n",
      "221: 147.59 s, 0 points\n",
      "222: 18.07 s, 0 points\n",
      "223: 46.43 s, 0 points\n",
      "224: 37.18 s, 0 points\n",
      "225: 58.46 s, 0 points\n",
      "226: 45.59 s, 0 points\n",
      "227: 28.90 s, 0 points\n",
      "228: 69.82 s, 0 points\n",
      "229: 58.12 s, 0 points\n",
      "230: 42.49 s, 0 points\n",
      "231: 38.63 s, 0 points\n",
      "232: 25.18 s, 0 points\n",
      "233: 16.21 s, 0 points\n",
      "234: 21.09 s, 0 points\n",
      "235: 25.50 s, 0 points\n",
      "236: 35.26 s, 0 points\n",
      "237: 34.54 s, 0 points\n",
      "238: 14.90 s, 0 points\n",
      "239: 19.81 s, 0 points\n",
      "240: 21.32 s, 0 points\n",
      "241: 17.38 s, 0 points\n",
      "242: 79.33 s, 95 points\n",
      "243: 49.03 s, 50 points\n",
      "244: 18.88 s, 0 points\n",
      "245: 29.89 s, 0 points\n",
      "246: 10.28 s, 0 points\n",
      "247: 37.11 s, 95 points\n",
      "248: 24.20 s, 40 points\n",
      "249: 25.37 s, 35 points\n",
      "250: 18.19 s, 100 points\n",
      "251: 51.48 s, 0 points\n",
      "252: 63.50 s, 0 points\n",
      "253: 15.79 s, 0 points\n",
      "254: 55.64 s, 0 points\n",
      "255: 26.69 s, 0 points\n",
      "256: 48.49 s, 0 points\n",
      "257: 43.18 s, 5 points\n",
      "258: 40.46 s, 0 points\n",
      "259: 19.35 s, 0 points\n",
      "260: 25.89 s, 0 points\n",
      "261: 40.00 s, 5 points\n",
      "262: 101.39 s, 10 points\n",
      "263: 37.68 s, 0 points\n",
      "264: 11.38 s, 0 points\n",
      "265: 41.46 s, 0 points\n",
      "266: 17.08 s, 0 points\n",
      "267: 61.10 s, 5 points\n",
      "268: 35.38 s, 0 points\n",
      "269: 32.53 s, 0 points\n",
      "270: 80.04 s, 0 points\n",
      "271: 26.20 s, 5 points\n",
      "272: 55.97 s, 0 points\n",
      "273: 25.61 s, 0 points\n",
      "274: 13.26 s, 0 points\n",
      "275: 147.29 s, 10 points\n",
      "276: 68.10 s, 0 points\n",
      "277: 95.35 s, 5 points\n",
      "278: 104.71 s, 0 points\n",
      "279: 44.66 s, 0 points\n",
      "280: 18.83 s, 0 points\n",
      "281: 53.15 s, 0 points\n",
      "282: 111.08 s, 0 points\n",
      "283: 27.78 s, 0 points\n",
      "284: 39.06 s, 40 points\n",
      "285: 16.07 s, 0 points\n",
      "286: 40.12 s, 0 points\n",
      "287: 22.42 s, 0 points\n",
      "288: 20.54 s, 0 points\n",
      "289: 24.66 s, 0 points\n",
      "290: 37.94 s, 80 points\n",
      "291: 29.28 s, 0 points\n",
      "292: 15.23 s, 0 points\n",
      "293: 23.36 s, 0 points\n",
      "294: 22.11 s, 0 points\n",
      "295: 102.39 s, 0 points\n",
      "296: 24.44 s, 0 points\n",
      "297: 21.58 s, 0 points\n",
      "298: 67.23 s, 5 points\n",
      "299: 138.46 s, 0 points\n",
      "300: 56.89 s, 0 points\n",
      "301: 63.33 s, 0 points\n",
      "302: 12.41 s, 80 points\n",
      "303: 17.51 s, 0 points\n",
      "304: 18.36 s, 0 points\n",
      "305: 27.46 s, 0 points\n",
      "306: 20.48 s, 0 points\n",
      "307: 88.65 s, 10 points\n",
      "308: 22.63 s, 0 points\n",
      "309: 22.68 s, 0 points\n",
      "310: 25.21 s, 0 points\n",
      "311: 12.86 s, 0 points\n",
      "312: 47.65 s, 0 points\n",
      "313: 43.35 s, 0 points\n",
      "314: 43.71 s, 0 points\n",
      "315: 17.41 s, 0 points\n",
      "316: 30.42 s, 0 points\n",
      "317: 65.16 s, 0 points\n",
      "318: 18.53 s, 0 points\n",
      "319: 26.03 s, 0 points\n",
      "320: 16.21 s, 0 points\n",
      "321: 33.11 s, 0 points\n",
      "322: 28.01 s, 0 points\n",
      "323: 19.42 s, 0 points\n",
      "324: 58.02 s, 0 points\n",
      "325: 72.47 s, 0 points\n",
      "326: 45.83 s, 0 points\n",
      "327: 11.77 s, 0 points\n",
      "328: 24.34 s, 0 points\n",
      "329: 45.64 s, 60 points\n",
      "330: 44.92 s, 5 points\n",
      "331: 17.93 s, 0 points\n",
      "332: 28.78 s, 0 points\n",
      "333: 40.03 s, 10 points\n",
      "334: 31.31 s, 0 points\n",
      "335: 42.20 s, 0 points\n",
      "336: 14.89 s, 0 points\n",
      "337: 50.21 s, 0 points\n",
      "338: 42.24 s, 0 points\n",
      "339: 30.27 s, 0 points\n",
      "340: 53.67 s, 0 points\n",
      "341: 218.22 s, 0 points\n",
      "342: 21.53 s, 0 points\n",
      "343: 23.21 s, 0 points\n",
      "344: 16.78 s, 0 points\n",
      "345: 28.80 s, 0 points\n",
      "346: 85.72 s, 0 points\n",
      "347: 66.66 s, 5 points\n",
      "348: 143.69 s, 0 points\n",
      "349: 62.14 s, 0 points\n",
      "350: 47.75 s, 0 points\n",
      "351: 36.30 s, 0 points\n",
      "352: 26.48 s, 0 points\n",
      "353: 42.66 s, 0 points\n",
      "354: 14.43 s, 0 points\n",
      "355: 33.10 s, 0 points\n",
      "356: 21.31 s, 0 points\n",
      "357: 34.76 s, 0 points\n",
      "358: 32.59 s, 0 points\n",
      "359: 17.63 s, 0 points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360: 10.90 s, 0 points\n",
      "361: 136.27 s, 0 points\n",
      "362: 23.71 s, 0 points\n",
      "363: 38.58 s, 0 points\n",
      "364: 29.56 s, 0 points\n",
      "365: 110.24 s, 0 points\n",
      "366: 133.72 s, 0 points\n",
      "367: 38.63 s, 0 points\n",
      "368: 37.30 s, 0 points\n",
      "369: 103.63 s, 5 points\n",
      "370: 35.80 s, 0 points\n",
      "371: 35.18 s, 0 points\n",
      "372: 38.39 s, 0 points\n",
      "373: 23.31 s, 0 points\n",
      "374: 90.94 s, 0 points\n",
      "375: 77.82 s, 0 points\n",
      "376: 58.82 s, 0 points\n",
      "377: 17.61 s, 0 points\n",
      "378: 33.12 s, 0 points\n",
      "379: 31.33 s, 0 points\n",
      "380: 99.15 s, 0 points\n",
      "381: 18.96 s, 0 points\n",
      "382: 61.49 s, 0 points\n",
      "383: 74.56 s, 5 points\n",
      "384: 13.20 s, 0 points\n",
      "385: 16.91 s, 0 points\n",
      "386: 14.12 s, 0 points\n",
      "387: 112.36 s, 0 points\n",
      "388: 38.38 s, 0 points\n",
      "389: 69.52 s, 0 points\n",
      "390: 44.63 s, 0 points\n",
      "391: 25.15 s, 0 points\n",
      "392: 57.26 s, 0 points\n",
      "393: 15.93 s, 0 points\n",
      "394: 43.41 s, 0 points\n",
      "395: 62.65 s, 0 points\n",
      "396: 252.96 s, 5 points\n",
      "397: 19.83 s, 0 points\n",
      "398: 31.50 s, 0 points\n",
      "399: 91.21 s, 0 points\n",
      "400: 189.12 s, 0 points\n",
      "401: 111.99 s, 5 points\n",
      "402: 17.46 s, 0 points\n",
      "403: 17.98 s, 0 points\n",
      "404: 50.34 s, 0 points\n",
      "405: 108.29 s, 0 points\n",
      "406: 21.49 s, 0 points\n",
      "407: 66.53 s, 0 points\n",
      "408: 37.38 s, 0 points\n",
      "409: 26.71 s, 0 points\n",
      "410: 40.99 s, 0 points\n",
      "411: 60.41 s, 20 points\n",
      "412: 96.31 s, 0 points\n",
      "413: 12.67 s, 0 points\n",
      "414: 37.36 s, 0 points\n",
      "415: 16.09 s, 0 points\n",
      "416: 71.30 s, 0 points\n",
      "417: 83.12 s, 0 points\n",
      "418: 42.10 s, 0 points\n",
      "419: 30.24 s, 0 points\n",
      "420: 35.13 s, 0 points\n",
      "421: 23.12 s, 0 points\n",
      "422: 45.83 s, 20 points\n",
      "423: 20.10 s, 0 points\n",
      "424: 42.46 s, 0 points\n",
      "425: 34.15 s, 0 points\n",
      "426: 59.94 s, 0 points\n",
      "427: 36.12 s, 0 points\n",
      "428: 37.52 s, 0 points\n",
      "429: 66.03 s, 5 points\n",
      "430: 65.96 s, 0 points\n",
      "431: 58.25 s, 0 points\n",
      "432: 91.93 s, 0 points\n",
      "433: 105.99 s, 5 points\n",
      "434: 13.63 s, 0 points\n",
      "435: 39.00 s, 0 points\n",
      "436: 18.48 s, 100 points\n",
      "437: 20.72 s, 0 points\n",
      "438: 28.10 s, 0 points\n",
      "439: 80.69 s, 5 points\n",
      "440: 36.24 s, 0 points\n",
      "441: 22.09 s, 0 points\n",
      "442: 62.72 s, 0 points\n",
      "443: 58.45 s, 145 points\n",
      "444: 82.78 s, 0 points\n",
      "445: 13.97 s, 0 points\n",
      "446: 26.01 s, 0 points\n",
      "447: 132.79 s, 10 points\n",
      "448: 47.90 s, 0 points\n",
      "449: 83.78 s, 0 points\n",
      "450: 51.28 s, 0 points\n",
      "451: 115.12 s, 55 points\n",
      "452: 18.18 s, 0 points\n",
      "453: 173.72 s, 0 points\n",
      "454: 68.92 s, 0 points\n",
      "455: 28.65 s, 0 points\n",
      "456: 103.55 s, 0 points\n",
      "457: 39.03 s, 0 points\n",
      "458: 58.64 s, 0 points\n",
      "459: 58.96 s, 5 points\n",
      "460: 16.64 s, 0 points\n",
      "461: 39.31 s, 0 points\n",
      "462: 245.52 s, 90 points\n",
      "463: 39.07 s, 0 points\n",
      "464: 50.91 s, 0 points\n",
      "465: 133.48 s, 0 points\n",
      "466: 87.91 s, 0 points\n",
      "467: 112.95 s, 0 points\n",
      "468: 25.84 s, 0 points\n",
      "469: 104.22 s, 30 points\n",
      "470: 60.87 s, 0 points\n",
      "471: 33.85 s, 0 points\n",
      "472: 62.21 s, 5 points\n",
      "473: 47.78 s, 55 points\n",
      "474: 45.77 s, 0 points\n",
      "475: 58.30 s, 0 points\n",
      "476: 75.56 s, 0 points\n",
      "477: 44.81 s, 0 points\n",
      "478: 90.22 s, 65 points\n",
      "479: 29.22 s, 0 points\n",
      "480: 106.99 s, 0 points\n",
      "481: 43.96 s, 5 points\n",
      "482: 161.85 s, 0 points\n",
      "483: 42.46 s, 75 points\n",
      "484: 19.60 s, 0 points\n",
      "485: 112.15 s, 0 points\n",
      "486: 61.32 s, 0 points\n",
      "487: 27.50 s, 0 points\n",
      "488: 36.50 s, 0 points\n",
      "489: 25.60 s, 0 points\n",
      "490: 46.93 s, 0 points\n",
      "491: 26.41 s, 0 points\n",
      "492: 49.21 s, 0 points\n",
      "493: 103.15 s, 0 points\n",
      "494: 51.83 s, 0 points\n",
      "495: 42.41 s, 0 points\n",
      "496: 47.84 s, 0 points\n",
      "497: 34.49 s, 0 points\n",
      "498: 142.38 s, 0 points\n",
      "499: 50.49 s, 0 points\n"
     ]
    }
   ],
   "source": [
    "# Train online\n",
    "# EPS_INIT = 0.1\n",
    "# EPS_MIN = 0.1\n",
    "# EPS_DECAY = 0.999\n",
    "# MAX_MEMORY = 1000\n",
    "# episode = play(500,\n",
    "#                train=True,\n",
    "#                useModel=True,\n",
    "#                modelFile='data/models/model_cnv3_lin_drp00_lr0001_e150_s3000_o1141.h5',\n",
    "# #                saveExp=True\n",
    "#               )\n",
    "\n",
    "\n",
    "# Save images\n",
    "# episode = play(50,\n",
    "#                saveExp=True   \n",
    "#               )\n",
    "\n",
    "\n",
    "# Play with model\n",
    "EPS_INIT = 0.9\n",
    "episode = play(500,\n",
    "               useModel=True, \n",
    "               modelFile='data/models/model_fqt_deepmind_mse_lr001_g9_e100_s3000.h5',\n",
    "#                saveExp=True\n",
    "#                train=True\n",
    "              )\n",
    "\n",
    "\n",
    "# Train offline\n",
    "# states, actions, labels, nextStates = readSamples(sampleFiles(3000))\n",
    "# # s2, a2, l2, n2 = readSamples(sampleFiles(50))\n",
    "# model = trainModelOffline(states, actions, labels, nextStates,\n",
    "#                           modelFunc=nn_model_deepmind,\n",
    "#                           epochs=100, \n",
    "#                           load=False, \n",
    "#                           file='data/models/model_fqt_deepmind_mse_lr001_g9_e100_s3000.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model structure\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "model = load_model('data/models/model.h5')\n",
    "plot_model(model, show_shapes=True, to_file='data/models/model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(episode):\n",
    "    for j, s in enumerate(e.state):\n",
    "        saveImage(s, 'data/shots2/e' + str(i) + '_c' + str(j) + '_' + moveString(e.action) + '_' + str(e.label) + '.png')\n",
    "    for j, s in enumerate(e.nextState):\n",
    "        saveImage(s, 'data/shots2/e' + str(i) + '_n' + str(j) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # s2, a2, l2, n2 = readSamples(sampleFiles(50))\n",
    "\n",
    "# model = load_model('data/models/model_cnv3_lin_drp00_lr0001_e150_s3000_o2700.h5')\n",
    "\n",
    "# for i, state in enumerate(s2):\n",
    "#     saveImage(state[1], 'data/shots2/s' + str(i) + '.png')\n",
    "# #     print(model.predict(np.asarray([state])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
